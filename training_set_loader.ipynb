{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faa81bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PACE] Applied profile A: default=0.15s, jitter=0.08s, cooldown=1.5s; overrides={'LeagueGameLog': 0.35, 'LeagueDashTeamStats': 0.25, 'LeagueDashPlayerStats': 0.3, 'TeamDashPtShots': 0.48, 'LeagueDashTeamShotLocations': 0.48, 'LeagueHustleStatsTeam': 0.55}\n",
      "league log shape: (2460, 29)\n",
      "  SEASON_ID     TEAM_ID TEAM_ABBREVIATION              TEAM_NAME     GAME_ID  \\\n",
      "0     22022  1610612738               BOS         Boston Celtics  0022200001   \n",
      "1     22022  1610612744               GSW  Golden State Warriors  0022200002   \n",
      "2     22022  1610612747               LAL     Los Angeles Lakers  0022200002   \n",
      "\n",
      "    GAME_DATE      MATCHUP WL  MIN  FGM  FGA  FG_PCT  FG3M  FG3A  FG3_PCT  \\\n",
      "0  2022-10-18  BOS vs. PHI  W  240   46   82   0.561    12    35    0.343   \n",
      "1  2022-10-18  GSW vs. LAL  W  240   45   99   0.455    16    45    0.356   \n",
      "2  2022-10-18    LAL @ GSW  L  240   40   94   0.426    10    40    0.250   \n",
      "\n",
      "   FTM  FTA  FT_PCT  OREB  DREB  REB  AST  STL  BLK  TOV  PF  PTS  PLUS_MINUS  \\\n",
      "0   22   28   0.786     6    30   36   24    8    3   11  24  126           9   \n",
      "1   17   23   0.739    11    37   48   31   11    4   18  23  123          14   \n",
      "2   19   25   0.760     9    39   48   23   12    4   22  18  109         -14   \n",
      "\n",
      "   VIDEO_AVAILABLE  \n",
      "0                1  \n",
      "1                1  \n",
      "2                1  \n",
      "after date normalize: (2460, 29)\n",
      "after routing predicate: (2460, 29)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import advanced_ledger\n",
    "from hustle_ledger import append_hustle_game\n",
    "import FourFactors_ledger\n",
    "import hustle_ledger\n",
    "import misc_ledger\n",
    "from misc_ledger import append_misc_game\n",
    "from FourFactors_ledger import append_FourFactors_game  # or append_fourfactors_game\n",
    "\n",
    "import shotloc_ptshot\n",
    "import os, importlib, stats_getter\n",
    "\n",
    "os.environ[\"NBA_PROXY_POOL\"] = (\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10011,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10022,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10034,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10036,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10037,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10038,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10460,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10464,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10466,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10467,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10476,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10483,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10501,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10502,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10505,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10507,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10511,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10516,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10522,\" # WORKS\n",
    "    \"http://spbi6ee2j0:jD7Pk~5fMlcV4ty2bt@dc.decodo.com:10524,\" # WORKS\n",
    "\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# FAST PROFILES: pacing & sleeps\n",
    "# ---------------------------\n",
    "import os, importlib\n",
    "import stats_getter\n",
    "import shotloc_ptshot\n",
    "\n",
    "# === Choose your profile ===\n",
    "#   \"A\" → Ambitious but safe (start here)\n",
    "#   \"B\" → Very aggressive (best with 2 processes on distinct proxies)\n",
    "PROFILE = os.getenv(\"NBA_PACING_PROFILE\", \"A\").strip().upper()\n",
    "# training_set_loader_copy.py\n",
    "# add near other imports\n",
    "from proxy_coord import acquire as proxy_acquire, release as proxy_release, apply_proxy as proxy_apply, current_proxy as proxy_current\n",
    "\n",
    "WORKER = os.environ.get(\"NBA_WORKER\", \"\").strip().upper() or \"X\"\n",
    "\n",
    "def _maybe_rotate_after_quota(worker: str, games_on_this_proxy: int) -> tuple[bool, int]:\n",
    "    \"\"\"\n",
    "    Returns (rotated, new_counter). Rotate after 3 games for proxies, 12 for DIRECT.\n",
    "    \"\"\"\n",
    "    cur = proxy_current()\n",
    "    quota = 12 if cur == \"DIRECT\" else 3\n",
    "    if games_on_this_proxy >= quota:\n",
    "        # release current and acquire another\n",
    "        proxy_release(worker, cur)\n",
    "        nxt = proxy_acquire(worker, exclude=cur)\n",
    "        if nxt:\n",
    "            proxy_apply(nxt)\n",
    "            print(f\"[proxy] ({worker}) post-quota rotate → {nxt} (quota={quota})\")\n",
    "        else:\n",
    "            # if nothing free, keep current; don't reset counter so we’ll try again next game\n",
    "            print(f\"[proxy] ({worker}) rotate wanted but none free; staying on {cur}\")\n",
    "            return False, games_on_this_proxy\n",
    "        return True, 0\n",
    "    return False, games_on_this_proxy\n",
    "\n",
    "def _ensure_proxy(worker: str, *, exclude: str | None = None):\n",
    "    \"\"\"Ensure we have a proxy reserved and applied for this worker.\"\"\"\n",
    "    cur = proxy_current()\n",
    "    if cur and (exclude is None or cur != exclude):\n",
    "        # already set; ensure it's reserved in state (idempotent acquire)\n",
    "        # try to acquire same proxy; if in use by other worker, get a new one\n",
    "        got = proxy_acquire(worker, exclude=None)  # may return a different one if cur is taken\n",
    "        if got and got != cur:\n",
    "            proxy_apply(got)\n",
    "            print(f\"[proxy] ({worker}) corrected reservation → {got}\")\n",
    "        return\n",
    "    nxt = proxy_acquire(worker, exclude=exclude)\n",
    "    if nxt:\n",
    "        proxy_apply(nxt)\n",
    "        print(f\"[proxy] ({worker}) initial → {nxt}\")\n",
    "\n",
    "\n",
    "# Profile definitions\n",
    "_profiles = {\n",
    "    \"A\": {\n",
    "        # env-level knobs (defaults for everything not overridden below)\n",
    "        \"NBA_STEADY_SLEEP\": 0.15,   # keep default for non-overridden endpoints\n",
    "        \"NBA_JITTER\":       0.08,   # ±0.04 s\n",
    "        \"NBA_GLOBAL_COOLDOWN\": 1.5,\n",
    "\n",
    "        # per-endpoint steady sleeps (seconds)\n",
    "        \"endpoint_sleeps\": {\n",
    "            \"LeagueGameLog\":               0.35,\n",
    "            \"LeagueDashTeamStats\":         0.25,\n",
    "            \"LeagueDashPlayerStats\":       0.30,\n",
    "            \"TeamDashPtShots\":             0.48,\n",
    "            \"LeagueDashTeamShotLocations\": 0.48,\n",
    "            \"LeagueHustleStatsTeam\":       0.55,\n",
    "        },\n",
    "    },\n",
    "    \"B\": {\n",
    "        \"NBA_STEADY_SLEEP\": 0.12,   # riskier default for everything else\n",
    "        \"NBA_JITTER\":       0.10,   # ±0.05 s\n",
    "        \"NBA_GLOBAL_COOLDOWN\": 1.2,\n",
    "\n",
    "        \"endpoint_sleeps\": {\n",
    "            \"LeagueGameLog\":               0.32,\n",
    "            \"LeagueDashTeamStats\":         0.22,\n",
    "            \"LeagueDashPlayerStats\":       0.24,\n",
    "            \"TeamDashPtShots\":             0.40,\n",
    "            \"LeagueDashTeamShotLocations\": 0.40,\n",
    "            \"LeagueHustleStatsTeam\":       0.46,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "_cfg = _profiles.get(PROFILE, _profiles[\"A\"])\n",
    "\n",
    "# 1) Apply env knobs (stats_getter reads these at import-time)\n",
    "os.environ.update({\n",
    "    \"NBA_STEADY_SLEEP\":      f'{_cfg[\"NBA_STEADY_SLEEP\"]}',\n",
    "    \"NBA_JITTER\":            f'{_cfg[\"NBA_JITTER\"]}',\n",
    "    \"NBA_GLOBAL_COOLDOWN\":   f'{_cfg[\"NBA_GLOBAL_COOLDOWN\"]}',\n",
    "    # keep your existing NBA_RETRIES / NBA_TIMEOUT as-is\n",
    "})\n",
    "\n",
    "# 2) Reload modules that capture env at import\n",
    "importlib.reload(stats_getter)\n",
    "importlib.reload(shotloc_ptshot)\n",
    "\n",
    "# 3) Per-endpoint overrides\n",
    "from stats_getter import STEADY_SLEEP_BY_ENDPOINT, PACE_GATES, PaceGate\n",
    "\n",
    "# Update the per-endpoint steady sleeps per the selected profile\n",
    "STEADY_SLEEP_BY_ENDPOINT.update(_cfg[\"endpoint_sleeps\"])\n",
    "\n",
    "# 4) Rebuild gates so new sleeps take effect immediately\n",
    "for ep, s in dict(STEADY_SLEEP_BY_ENDPOINT).items():\n",
    "    PACE_GATES[ep] = PaceGate(s)\n",
    "\n",
    "print(f\"[PACE] Applied profile {PROFILE}: \"\n",
    "      f\"default={_cfg['NBA_STEADY_SLEEP']}s, jitter={_cfg['NBA_JITTER']}s, \"\n",
    "      f\"cooldown={_cfg['NBA_GLOBAL_COOLDOWN']}s; \"\n",
    "      f\"overrides={_cfg['endpoint_sleeps']}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from advanced_first_game import poss_first_game_mixed\n",
    "from advanced_ledger import _save_ledger, get_advanced_team_game_rows\n",
    "import features_loader_copy\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from nba_api.stats.endpoints import LeagueDashTeamShotLocations, teamgamelog, LeagueDashPlayerStats, playergamelogs, PlayerGameLogs, HustleStatsBoxScore, BoxScoreAdvancedV2, LeagueGameLog,  LeagueDashTeamStats, LeagueDashTeamClutch, LeagueHustleStatsTeam, TeamGameLog, TeamGameLogs\n",
    "from nba_api.stats.static import teams\n",
    "import importlib\n",
    "from features_loader_copy import getTeamAstTovRosterChange_on_date\n",
    "from stats_getter import build_hustle_subset, first_n_game_ids_for_team, getLeagueDashPlayerStats, get_player_id, getRoster\n",
    "importlib.reload(features_loader_copy)\n",
    "importlib.reload(hustle_ledger)\n",
    "from features_loader_copy import *\n",
    "from typing import Dict\n",
    "import cache_manager\n",
    "from cache_manager import stats_cache\n",
    "import time\n",
    "import random\n",
    "\n",
    "# In training_set_loader.ipynb\n",
    "\n",
    "from importlib import reload\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---- first_game_cache.py (inline in your file is fine) ----\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# (season, team) -> pd.Timestamp (earliest date)\n",
    "_FIRST_GAME_CACHE = {}\n",
    "_TRAINING_SIG = None  # (mtime_ns, size)\n",
    "\n",
    "from functools import lru_cache\n",
    "from stats_getter import get_league_game_log, getLeagueHustleTeamStats\n",
    "# you already import `teams` earlier: from nba_api.stats.static import teams\n",
    "\n",
    "# --- helpers used by the functions below ---\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import math, time\n",
    "\n",
    "\n",
    "import stats_getter\n",
    "\n",
    "from advanced_ledger import append_adv_game\n",
    "\n",
    "\n",
    "def _seasons_from_env(seasons: list[str]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Override the seasons list from environment.\n",
    "    - NBA_SEASONS=\"2019-20,2020-21\" → explicit list\n",
    "    - NBA_WORKER in {\"A\",\"B\"} → partition default list so A/B don’t collide\n",
    "    \"\"\"\n",
    "    import os\n",
    "    env = os.getenv(\"NBA_SEASONS\", \"\").strip()\n",
    "    if env:\n",
    "        out = [s.strip() for s in env.split(\",\") if s.strip()]\n",
    "        return out or seasons\n",
    "\n",
    "    # Partition by worker label (optional convenience)\n",
    "    worker = os.getenv(\"NBA_WORKER\", \"\").strip().upper()\n",
    "    if worker == \"A\":\n",
    "        wanted = {\"2015-16\",\"2016-17\",\"2017-18\",\"2018-19\",\"2019-20\"}\n",
    "        return [s for s in seasons if s in wanted] or seasons\n",
    "    if worker == \"B\":\n",
    "        wanted = {\"2020-21\",\"2021-22\",\"2022-23\",\"2023-24\",\"2024-25\"}\n",
    "        return [s for s in seasons if s in wanted] or seasons\n",
    "    return seasons\n",
    "\n",
    "def get_season_games(season):\n",
    "    \"\"\"Get all games for a season from your existing data\"\"\"\n",
    "    # Read from your training_set.csv or use the league game log\n",
    "    df = pd.read_csv('training_set.csv')\n",
    "    df_season = df[df['season'] == season].copy()\n",
    "    \n",
    "    # If no data in training_set, get from API\n",
    "    if df_season.empty:\n",
    "        df_league = get_league_game_log(season)\n",
    "        # Process to get unique games (home/away pairs)\n",
    "        games = []\n",
    "        seen_games = set()\n",
    "        \n",
    "        for _, row in df_league.iterrows():\n",
    "            game_id = row['GAME_ID']\n",
    "            if game_id not in seen_games:\n",
    "                seen_games.add(game_id)\n",
    "                # Determine home/away from MATCHUP\n",
    "                if '@' in row['MATCHUP']:\n",
    "                    # This team is away\n",
    "                    continue\n",
    "                else:\n",
    "                    # This team is home\n",
    "                    home_team = row['TEAM_NAME']\n",
    "                    # Find corresponding away team row\n",
    "                    away_row = df_league[\n",
    "                        (df_league['GAME_ID'] == game_id) & \n",
    "                        (df_league['TEAM_ID'] != row['TEAM_ID'])\n",
    "                    ].iloc[0]\n",
    "                    away_team = away_row['TEAM_NAME']\n",
    "                    \n",
    "                    games.append({\n",
    "                        'date': row['GAME_DATE'],\n",
    "                        'home_team': home_team,\n",
    "                        'away_team': away_team,\n",
    "                        'season': season\n",
    "                    })\n",
    "        \n",
    "        df_season = pd.DataFrame(games)\n",
    "    \n",
    "    return df_season\n",
    "\n",
    "def get_previous_season(season):\n",
    "    \"\"\"Get the previous season string from current season\"\"\"\n",
    "    try:\n",
    "        start_year = int(season.split('-')[0])\n",
    "        prev_start = start_year - 1\n",
    "        prev_end = start_year\n",
    "        return f\"{prev_start}-{str(prev_end)[2:]}\"\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def _resolve_game_id(season: str, home_team: str, away_team: str, date_str: str) -> str | None:\n",
    "    \"\"\"\n",
    "    Robustly find GAME_ID for (season, home_team vs away_team) on date_str (MM/DD/YYYY).\n",
    "    Prefers the 'home' row (MATCHUP contains 'vs'). Returns a 10-char string or None.\n",
    "    \"\"\"\n",
    "    lg = stats_getter.get_league_game_log(season).copy()\n",
    "    lg[\"GAME_DATE\"] = pd.to_datetime(lg[\"GAME_DATE\"]).dt.normalize()\n",
    "    day = pd.to_datetime(date_str).normalize()\n",
    "\n",
    "    day_rows = lg[lg[\"GAME_DATE\"] == day]\n",
    "    if day_rows.empty:\n",
    "        return None\n",
    "\n",
    "    # Prefer explicit home row\n",
    "    home_row = day_rows[\n",
    "        (day_rows[\"TEAM_NAME\"] == home_team) &\n",
    "        (day_rows[\"MATCHUP\"].astype(str).str.contains(\"vs\", case=False, regex=False))\n",
    "    ]\n",
    "    if not home_row.empty:\n",
    "        return str(home_row.iloc[0][\"GAME_ID\"]).zfill(10)\n",
    "\n",
    "    # Fallback: group with exactly these two teams\n",
    "    cand = day_rows[day_rows[\"TEAM_NAME\"].isin([home_team, away_team])]\n",
    "    grp = cand.groupby(\"GAME_ID\").filter(lambda g: set(g[\"TEAM_NAME\"]) == {home_team, away_team})\n",
    "    if not grp.empty:\n",
    "        return str(grp.iloc[0][\"GAME_ID\"]).zfill(10)\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _ensure_first_game_cache(path: str = \"training_set.csv\"):\n",
    "    \"\"\"\n",
    "    Build/refresh { (season, team) -> first_game_date } if the CSV changed.\n",
    "    \"\"\"\n",
    "    global _FIRST_GAME_CACHE, _TRAINING_SIG\n",
    "    st = os.stat(path)  # raises if missing\n",
    "    sig = (st.st_mtime_ns, st.st_size)\n",
    "    if sig == _TRAINING_SIG and _FIRST_GAME_CACHE:\n",
    "        return  # already fresh\n",
    "\n",
    "    df = pd.read_csv(path, usecols=[\"season\", \"date\", \"home_team\", \"away_team\"])\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "\n",
    "    homes = df[[\"season\", \"home_team\", \"date\"]].rename(columns={\"home_team\": \"team\"})\n",
    "    aways = df[[\"season\", \"away_team\", \"date\"]].rename(columns={\"away_team\": \"team\"})\n",
    "    all_rows = pd.concat([homes, aways], ignore_index=True)\n",
    "\n",
    "    first = all_rows.groupby([\"season\", \"team\"], sort=False)[\"date\"].min()\n",
    "    # Convert to plain dict with tuple keys\n",
    "    _FIRST_GAME_CACHE = {(s, t): d for (s, t), d in first.items()}\n",
    "    _TRAINING_SIG = sig\n",
    "\n",
    "def is_first_game_of_season(team_name: str, season: str, date_str: str, path: str = \"training_set.csv\") -> bool:\n",
    "    \"\"\"\n",
    "    O(1) check with cached CSV: no repeated reads.\n",
    "    \"\"\"\n",
    "    _ensure_first_game_cache(path)\n",
    "    first = _FIRST_GAME_CACHE.get((season, team_name))\n",
    "    if first is None or pd.isna(first):\n",
    "        return False\n",
    "    target = pd.to_datetime(date_str, errors=\"coerce\")\n",
    "    if pd.isna(target):\n",
    "        raise ValueError(\"date_str must be MM/DD/YYYY\")\n",
    "    return target.normalize() == first.normalize()\n",
    "# ---- end first_game_cache ----\n",
    "\n",
    "def build_dataset_for_window(\n",
    "    start_date=\"10/26/2015\",\n",
    "    end_date=\"11/26/2015\",\n",
    "    seasons=(\"2015-16\",),\n",
    "    output_file=\"nba_features_2015-10-26_to_2016-11-26.csv\",\n",
    "    save_every=10,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Build a features dataset only for games between start_date and end_date (inclusive),\n",
    "    over the provided seasons. Appends the current game to the advanced ledger\n",
    "    **after** computing features (so priors evolve naturally).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        globals()['get_adaptive_delay'] = lambda operation_type='default', attempt_number=1: 0.0\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    rows = []\n",
    "    total_seen = 0\n",
    "    start = pd.to_datetime(start_date, format=\"%m/%d/%Y\")\n",
    "    end   = pd.to_datetime(end_date,   format=\"%m/%d/%Y\")\n",
    "\n",
    "    for season in seasons:\n",
    "        df_games = get_season_games(season).copy()\n",
    "        if df_games.empty:\n",
    "            print(f\"[{season}] No games found in training_set.csv or via fallback.\")\n",
    "            continue\n",
    "\n",
    "        df_games['date'] = pd.to_datetime(df_games['date'], format=\"%m/%d/%Y\", errors='coerce')\n",
    "        df_games = df_games[(df_games['date'] >= start) & (df_games['date'] <= end)]\n",
    "        df_games = df_games.sort_values('date').reset_index(drop=True)\n",
    "        if df_games.empty:\n",
    "            print(f\"[{season}] No games in window {start_date}–{end_date}.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing {len(df_games)} games for {season} within {start_date}–{end_date}...\")\n",
    "        for _, g in df_games.iterrows():\n",
    "            dstr = g['date'].strftime(\"%m/%d/%Y\"); home = g['home_team']; away = g['away_team']\n",
    "            try:\n",
    "                feats = calculate_game_features(home_team=home, away_team=away, date=dstr, season=season)\n",
    "                feats['date'] = dstr; feats['home_team'] = home; feats['away_team'] = away; feats['season'] = season\n",
    "                for col in [\"home_money_line\",\"away_money_line\",\"home_spread\",\"away_spread\",\"home_score\",\"away_score\"]:\n",
    "                    if col in g.index: feats[col] = g[col]\n",
    "                rows.append(feats)\n",
    "                total_seen += 1\n",
    "                print(f\"Game between {home} and {away} on {dstr} was recorded\")\n",
    "\n",
    "                if total_seen % int(save_every) == 0:\n",
    "                    pd.DataFrame(rows).to_csv(output_file, index=False)\n",
    "                    print(f\"Saved progress after {total_seen} games -> {output_file}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Skipped {home} vs {away} on {dstr} ({season}): {e}\")\n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    if not df_out.empty:\n",
    "        df_out.to_csv(output_file, index=False)\n",
    "        print(f\"✅ Done. Wrote {len(df_out)} games to {output_file}\")\n",
    "    else:\n",
    "        print(\"No rows written (empty selection or all failed).\")\n",
    "    return df_out\n",
    "\n",
    "\n",
    "\n",
    "def initialize_features_dataframe():\n",
    "    \"\"\"Initialize DataFrame with all feature columns\"\"\"\n",
    "    base_columns = ['date', 'home_team', 'away_team', 'season', 'home_money_line', 'away_money_line', 'home_spread', 'away_spread', 'home_score', 'away_score']\n",
    "    \n",
    "    feature_columns = [\n",
    "        # General Features (2)\n",
    "        'home_b2b', 'away_b2b',\n",
    "        \n",
    "        # General Defensive Features (2)\n",
    "        'stocks_deflections_diff', 'pf_diff',\n",
    "        \n",
    "        # General Offensive Features (2)\n",
    "        'pace_ratio', 'clutch_netrtg_ratio',\n",
    "        \n",
    "        # Free Throw Shooting Features (2)\n",
    "        'fta_rate_relative', 'pfd_diff',\n",
    "        \n",
    "        # Rebounding Features (3)\n",
    "        'dreb_pct_relative', 'oreb_pct_relative', 'second_chance_pts_rate',\n",
    "        \n",
    "        # Playmaking Features (4)\n",
    "        'assist_ratio_relative', 'turnover_ratio_relative', \n",
    "        'pct_ast_fgm_ratio', 'screen_assists_diff',\n",
    "        \n",
    "        # 3PT Shooting Features (4)\n",
    "        'contested_3pt_rate', 'open_3pt_rate',\n",
    "        'corner_3pt_rate', 'above_break_3pt_rate',\n",
    "        \n",
    "        # 2PT Shooting Features (4)\n",
    "        'paint_shot_rate', 'midrange_shot_rate',\n",
    "        'contested_2pt_rate', 'open_2pt_rate',\n",
    "        \n",
    "        # Misc Scoring Features (2)\n",
    "        'pts_off_tov_rate', 'pts_fastbreak_rate',\n",
    "        \n",
    "        # Last 5 Games Features (5)\n",
    "        'recent_netrtg_ratio', 'recent_oreb_pct_ratio', 'recent_efg_pct_ratio',\n",
    "        'recent_tov_pct_ratio', 'recent_ft_rate_ratio',\n",
    "        \n",
    "        # Additional Features (14)\n",
    "        'home_last_season_netrtg', 'away_last_season_netrtg',\n",
    "        'home_last_season_oreb_pct', 'away_last_season_oreb_pct',\n",
    "        'home_last_season_efg_pct', 'away_last_season_efg_pct',\n",
    "        'home_last_season_tov_pct', 'away_last_season_tov_pct',\n",
    "        'home_last_season_ft_rate', 'away_last_season_ft_rate',\n",
    "        'home_netrtg_diff_prev_season', 'away_netrtg_diff_prev_season',\n",
    "        'home_game_number', 'away_game_number',\n",
    "        \n",
    "        # NEW Roster Change Features (8) - Features 45-52\n",
    "        'home_ppg_diff_prev_season', 'away_ppg_diff_prev_season',\n",
    "        'home_ast_tov_diff_prev_season', 'away_ast_tov_diff_prev_season', \n",
    "        'home_def_rating_diff_prev_season', 'away_def_rating_diff_prev_season',\n",
    "        'home_usg_rate_lost_prev_season', 'away_usg_rate_lost_prev_season'\n",
    "    ]\n",
    "    \n",
    "    all_columns = base_columns + feature_columns\n",
    "    return pd.DataFrame(columns=all_columns)\n",
    "\n",
    "def get_team_season_for_stats(is_first_game, current_season):\n",
    "    \"\"\"Returns the appropriate season to use for stats based on game status\"\"\"\n",
    "    if is_first_game:\n",
    "        return get_previous_season(current_season)\n",
    "    else:\n",
    "        return current_season\n",
    "\n",
    "def load_all_features(seasons=None, output_file='nba_features_2015_2025.csv'):\n",
    "    \"\"\"\n",
    "    Load all 52 features for NBA games from 2015-16 through 2024-25\n",
    "    \"\"\"\n",
    "    if seasons is None:\n",
    "        seasons = ['2015-16', '2016-17', '2017-18', '2018-19', '2019-20', \n",
    "                   '2020-21', '2021-22', '2022-23', '2023-24', '2024-25']\n",
    "        \n",
    "    seasons = _seasons_from_env(seasons)\n",
    "    # Initialize results DataFrame\n",
    "    all_features_df = initialize_features_dataframe()\n",
    "    \n",
    "    # Process each season\n",
    "    for season in seasons:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing season: {season}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            season_features = process_season(season)\n",
    "            all_features_df = pd.concat([all_features_df, season_features], \n",
    "                                       ignore_index=True)\n",
    "            \n",
    "            # Save intermediate results after each season\n",
    "            all_features_df.to_csv(f'{output_file}.temp', index=False)\n",
    "            print(f\"✅ Completed {season} - {len(season_features)} games processed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            import traceback\n",
    "\n",
    "            # 1) Print the full stack trace (most helpful)\n",
    "            print(f\"❌ Error processing {season}: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "            # 2) Also print the *origin* of the exception (deepest frame)\n",
    "            tb = e.__traceback__\n",
    "            while tb.tb_next:          # walk to the last frame\n",
    "                tb = tb.tb_next\n",
    "            frame = tb.tb_frame\n",
    "            func  = frame.f_code.co_name\n",
    "            file  = frame.f_code.co_filename\n",
    "            line  = tb.tb_lineno\n",
    "            print(f\"↳ Origin: {func} at {file}:{line}\")\n",
    "\n",
    "            continue\n",
    "    \n",
    "    # Save final results\n",
    "    all_features_df.to_csv(output_file, index=False)\n",
    "    print(f\"\\n✅ All features saved to {output_file}\")\n",
    "    print(f\"Total games processed: {len(all_features_df)}\")\n",
    "    \n",
    "    return all_features_df\n",
    "\n",
    "def process_season(season, mutate_ledgers: bool = True):\n",
    "    timeline_curr = get_roster_timeline(season)\n",
    "    prev_season = get_previous_season(season)\n",
    "    timeline_prev = get_roster_timeline(prev_season)\n",
    "    df_games = get_season_games(season)\n",
    "    season_features = []\n",
    "\n",
    "    # Preload league log once to resolve GAME_IDs cheaply\n",
    "    from stats_getter import get_team_id, get_league_game_log\n",
    "    league_log = get_league_game_log(season).copy()\n",
    "    league_log[\"_DATE\"] = pd.to_datetime(league_log[\"GAME_DATE\"], errors=\"coerce\").dt.normalize()\n",
    "\n",
    "    def _resolve_game_id(date_str, home_name, away_name):\n",
    "        import pandas as pd\n",
    "        hid, aid = get_team_id(home_name), get_team_id(away_name)\n",
    "        if hid is None or aid is None:\n",
    "            return None\n",
    "        d = pd.to_datetime(date_str, errors=\"coerce\").normalize()\n",
    "        rows = league_log[(league_log[\"_DATE\"] == d) & (league_log[\"TEAM_ID\"].isin([hid, aid]))]\n",
    "        gids = rows[\"GAME_ID\"].dropna().unique().tolist()\n",
    "        if len(gids) == 1:\n",
    "            return str(gids[0])\n",
    "        for gid in gids:\n",
    "            sub = league_log[league_log[\"GAME_ID\"] == gid]\n",
    "            if set(sub[\"TEAM_ID\"].unique()).issuperset({hid, aid}):\n",
    "                return str(gid)\n",
    "        return None\n",
    "    \n",
    "    _ensure_proxy(WORKER)\n",
    "    games_on_this_proxy = 0\n",
    "\n",
    "    for idx, game in df_games.iterrows():\n",
    "        rotated, games_on_this_proxy = _maybe_rotate_after_quota(WORKER, games_on_this_proxy)\n",
    "        if rotated:\n",
    "            pass\n",
    "        date_str = game['date'] if isinstance(game['date'], str) else game['date'].strftime(\"%m/%d/%Y\")\n",
    "\n",
    "        feats = calculate_game_features(\n",
    "            home_team=game['home_team'],\n",
    "            away_team=game['away_team'],\n",
    "            date=game['date'],\n",
    "            season=season\n",
    "        )\n",
    "        games_on_this_proxy += 1\n",
    "        feats.update({'date': game['date'], 'home_team': game['home_team'], 'away_team': game['away_team'], 'season': season})\n",
    "        season_features.append(feats)\n",
    "        \n",
    "        # ← mutate AFTER computing features so priors were truly \"up to day-before\"\n",
    "        if mutate_ledgers:\n",
    "            gid = _resolve_game_id(date_str, game['home_team'], game['away_team'])\n",
    "            if gid:\n",
    "                from advanced_ledger import append_adv_game  # or ensure_advanced_for_game if you want *_prior columns populated\n",
    "                append_adv_game(season, gid)\n",
    "                append_misc_game(season, gid)\n",
    "                append_FourFactors_game(season, gid)\n",
    "                append_hustle_game(season, gid)\n",
    "\n",
    "    return pd.DataFrame(season_features)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def _eff_ratio(getter, a_team, b_team, a_season, b_season, dstr):\n",
    "    a = getter(a_team, a_season, dstr)\n",
    "    b = getter(b_team, b_season, dstr)\n",
    "    try:\n",
    "        return a / b if (b not in (0, None) and not np.isnan(b)) else np.nan\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def calculate_game_features(home_team, away_team, date, season):\n",
    "    \"\"\"\n",
    "    Returns a dict whose keys align 1:1 with initialize_features_dataframe().\n",
    "    - Warms advanced ledger up to (date) for stability.\n",
    "    - Uses cached first-game check to swap prior-season where needed.\n",
    "    - Keeps hustle/first-game mixed fallbacks.\n",
    "    \"\"\"\n",
    "    import numpy as np, time\n",
    "    from datetime import datetime\n",
    "\n",
    "    from stats_getter import canon_team\n",
    "\n",
    "    home_team = canon_team(home_team)\n",
    "    away_team = canon_team(away_team)\n",
    "\n",
    "    print(home_team, away_team)\n",
    "\n",
    "\n",
    "    # ---------- setup ----------\n",
    "    features = {}\n",
    "    feature_times = {}\n",
    "\n",
    "    # normalize date to \"MM/DD/YYYY\"\n",
    "    date_str = date if isinstance(date, str) else date.strftime(\"%m/%d/%Y\")\n",
    "\n",
    "        # --- print league-wide game number like \"game 3/1230\" ---\n",
    "    try:\n",
    "        # League log → de-dup to 1 row per GAME_ID, sort by date then GAME_ID\n",
    "        lg = get_league_game_log(season).copy()\n",
    "        lg[\"GAME_DATE\"] = pd.to_datetime(lg[\"GAME_DATE\"]).dt.normalize()\n",
    "        games = (\n",
    "            lg[[\"GAME_ID\", \"GAME_DATE\"]]\n",
    "            .drop_duplicates()\n",
    "            .sort_values([\"GAME_DATE\", \"GAME_ID\"])\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "        total_games = len(games)\n",
    "\n",
    "        # Find this matchup's GAME_ID and its 1-based position\n",
    "        gid = _resolve_game_id(season, home_team, away_team, date_str)\n",
    "        if gid:\n",
    "            mask = games[\"GAME_ID\"].astype(str) == str(gid)\n",
    "            idx_list = games.index[mask].tolist()\n",
    "            if idx_list:\n",
    "                print(f\"📅 game {idx_list[0] + 1}/{total_games}\")\n",
    "            else:\n",
    "                print(f\"📅 game ?/{total_games} (unresolved GAME_ID position)\")\n",
    "        else:\n",
    "            print(f\"📅 game ?/{total_games} (couldn't resolve GAME_ID)\")\n",
    "    except Exception as e:\n",
    "        print(f\"(game index print skipped: {e})\")\n",
    "\n",
    "\n",
    "    # Per-team season selection (prior season on first game)\n",
    "    home_is_first = is_first_game_of_season(home_team, season, date_str)\n",
    "    away_is_first = is_first_game_of_season(away_team, season, date_str)\n",
    "    home_season   = get_previous_season(season) if home_is_first else season\n",
    "    away_season   = get_previous_season(season) if away_is_first else season\n",
    "    first_game_any = home_is_first or away_is_first\n",
    "\n",
    "    def try_feature(name, func, *args, **kwargs):\n",
    "        t0 = time.perf_counter()\n",
    "        try:\n",
    "            features[name] = func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {name}: {e}\")\n",
    "            features[name] = np.nan\n",
    "        finally:\n",
    "            feature_times[name] = time.perf_counter() - t0\n",
    "            print(f\"⏱  {name:35s} {feature_times[name]:7.4f}s\")\n",
    "\n",
    "    # ---------- General ----------\n",
    "    try_feature('home_b2b', getB2B, home_team, home_season, date_str) # 100%\n",
    "    try_feature('away_b2b', getB2B, away_team, away_season, date_str) # 100%\n",
    "\n",
    "    # ---------- Hustle (stocks/deflections + screens) ----------\n",
    "    if season == \"2015-16\" or season == \"2016-17\":\n",
    "        # DEFLECTIONS unreliable in 2015-16 and 2016-17 → use stocks-only; screens only if not first-game\n",
    "        try_feature(\"stocks_deflections_diff\", getStockDiff,\n",
    "                    home_team, away_team, home_season, away_season, date_str)\n",
    "        if first_game_any:\n",
    "            features[\"screen_assists_diff\"] = np.nan\n",
    "            feature_times[\"screen_assists_diff\"] = 0.0\n",
    "            print(f\"⏱  {'screen_assists_diff (2015-16 first-game)':35s} {0.0:7.4f}s\")\n",
    "        else:\n",
    "            try_feature(\"screen_assists_diff\", screenAssistDiff,\n",
    "                        home_team, away_team, home_season, away_season, date_str)\n",
    "    else:\n",
    "        # 2016-17+: if it is the first game of the season we will not call the expensive leaguehustleteamstats endpoint\n",
    "        if first_game_any:\n",
    "            try_feature(\"stocks_deflections_diff\", getStockDiff,\n",
    "                        home_team, away_team, home_season, away_season, date_str)\n",
    "            features[\"screen_assists_diff\"] = np.nan\n",
    "            \n",
    "        else:\n",
    "            try_feature(\"stocks_deflections_diff\", stocksDeflectionDiff,\n",
    "                        home_team, away_team, home_season, away_season, date_str)\n",
    "            try_feature(\"screen_assists_diff\", screenAssistDiff,\n",
    "                        home_team, away_team, home_season, away_season, date_str)\n",
    "\n",
    "    # Always include PF diff (general defense)\n",
    "    try_feature('pf_diff', get_pf_diff, home_team, away_team, home_season, away_season, date_str)\n",
    "\n",
    "    # ---------- General offense ----------\n",
    "    # PACE ratio (mixed on first game; otherwise your normal getter)\n",
    "    if first_game_any:\n",
    "        try_feature('pace_ratio', pace_ratio_first_game_mixed,\n",
    "                    home_team, away_team, home_season, away_season, date_str)\n",
    "    else:\n",
    "        try_feature('pace_ratio', get_pace_diff,\n",
    "                    home_team, away_team, home_season, away_season, date_str)\n",
    "\n",
    "    # CLUTCH NETRTG ratio (missing before; now added)\n",
    "    try_feature('clutch_netrtg_ratio', get_clutch_netrtg_ratio,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "\n",
    "    # ---------- Free throws ----------\n",
    "    try_feature('fta_rate_relative', get_fta_rate_relative_ratio, # DEBUGGED\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('pfd_diff', get_pfd_diff,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "\n",
    "    # ---------- Rebounding ----------\n",
    "    # Use your mixed fallbacks for the first game, otherwise relative getters\n",
    "    if first_game_any:\n",
    "        try_feature('dreb_pct_relative', dreb_pct_diff_first_game_mixed,\n",
    "                    home_team, away_team, home_season, away_season, date_str)\n",
    "        try_feature('oreb_pct_relative', oreb_pct_diff_first_game_mixed,\n",
    "                    home_team, away_team, home_season, away_season, date_str)\n",
    "    else:\n",
    "        try_feature('dreb_pct_relative', get_dreb_pct_relative_diff,\n",
    "                    home_team, away_team, home_season, away_season, date_str)\n",
    "        try_feature('oreb_pct_relative', get_oreb_pct_relative_diff,\n",
    "                    home_team, away_team, home_season, away_season, date_str)\n",
    "\n",
    "    # Second-chance points rate (ratio)\n",
    "    try:\n",
    "        h_2nd = misc_ledger.get_second_chance_pts_per_100(home_team, home_season, date_str)\n",
    "        a_2nd = misc_ledger.get_second_chance_pts_per_100(away_team, away_season, date_str)\n",
    "        features['second_chance_pts_rate'] = (h_2nd / a_2nd) if a_2nd else np.nan\n",
    "    except Exception as e:\n",
    "        print(f\"Error in second_chance_pts_rate: {e}\")\n",
    "        features['second_chance_pts_rate'] = np.nan\n",
    "\n",
    "    # ---------- Playmaking ----------\n",
    "    try_feature('assist_ratio_relative', get_assist_ratio_relative_ratio,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('turnover_ratio_relative', get_turnover_ratio_relative,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('pct_ast_fgm_ratio', get_pct_ast_fgm_ratio,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "\n",
    "    # ---------- 3PT shooting (directional: home→away & away→home) ----------\n",
    "    # PT SHOTS buckets (defender distance)\n",
    "    try_feature('contested_3pt_rate_home', contested_3pt_rate,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('contested_3pt_rate_away', contested_3pt_rate,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "    try_feature('contested_3pt_eff_home', contested_3pt_efficiency,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('contested_3pt_eff_away', contested_3pt_efficiency,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "\n",
    "    try_feature('open_3pt_rate_home', open_3pt_rate,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('open_3pt_rate_away', open_3pt_rate,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "    try_feature('open_3pt_eff_home', open_3pt_efficiency,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('open_3pt_eff_away', open_3pt_efficiency,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "\n",
    "    # SHOT-LOCATION buckets (zones)\n",
    "    try_feature('corner_3pt_rate_home', corner_3pt_rate,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('corner_3pt_rate_away', corner_3pt_rate,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "    try_feature('corner_3pt_eff_home', corner_3pt_efficiency,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('corner_3pt_eff_away', corner_3pt_efficiency,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "\n",
    "    try_feature('above_break_3pt_rate_home', above_break_3pt_rate,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('above_break_3pt_rate_away', above_break_3pt_rate,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "    try_feature('above_break_3pt_eff_home', above_break_3pt_efficiency,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('above_break_3pt_eff_away', above_break_3pt_efficiency,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "\n",
    "    # ---------- 2PT shooting (directional) ----------\n",
    "    # SHOT-LOCATION buckets (paint, midrange)\n",
    "    try_feature('paint_shot_rate_home', paint_shot_rate,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('paint_shot_rate_away', paint_shot_rate,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "    try_feature('paint_shot_eff_home', paint_shot_efficiency,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('paint_shot_eff_away', paint_shot_efficiency,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "\n",
    "    try_feature('midrange_shot_rate_home', midrange_shot_rate,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('midrange_shot_rate_away', midrange_shot_rate,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "    try_feature('midrange_shot_eff_home', midrange_shot_efficiency,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('midrange_shot_eff_away', midrange_shot_efficiency,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "\n",
    "    # PT SHOTS buckets (defender distance) — 2PT\n",
    "    try_feature('contested_2pt_rate_home', contested_2pt_rate,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('contested_2pt_rate_away', contested_2pt_rate,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "    try_feature('contested_2pt_eff_home', contested_2pt_efficiency,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('contested_2pt_eff_away', contested_2pt_efficiency,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "\n",
    "    try_feature('open_2pt_rate_home', open_2pt_rate,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('open_2pt_rate_away', open_2pt_rate,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "    try_feature('open_2pt_eff_home', open_2pt_efficiency,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('open_2pt_eff_away', open_2pt_efficiency,\n",
    "                away_team, home_team, away_season, home_season, date_str)\n",
    "\n",
    "\n",
    "\n",
    "    # ---------- Misc scoring ----------\n",
    "    try_feature('pts_off_tov_rate_relative', misc_ledger.get_pts_off_tov_rate_relative,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "    try_feature('pts_fastbreak_rate_relative', misc_ledger.get_pts_fb_ratio,\n",
    "                home_team, away_team, home_season, away_season, date_str)\n",
    "\n",
    "    # ---------- Last 5 games ----------\n",
    "    try_feature('recent_netrtg_ratio', get_recent_netrtg_ratio,\n",
    "                home_team, away_team, season, season, date_str)\n",
    "    try_feature('recent_oreb_pct_ratio', get_recent_oreb_pct_ratio,\n",
    "                home_team, away_team, season, season, date_str)\n",
    "    try_feature('recent_efg_pct_ratio', get_recent_efg_pct_ratio,\n",
    "                home_team, away_team, season, season, date_str)\n",
    "    try_feature('recent_tov_pct_ratio', get_recent_tov_pct_ratio,\n",
    "                home_team, away_team, season, season, date_str)\n",
    "    \n",
    "    try_feature('recent_ft_rate_ratio', get_recent_ft_rate_ratio,\n",
    "                home_team, away_team, season, season, date_str)\n",
    "\n",
    "    # ---------- Prior-season anchors ----------\n",
    "    try_feature('home_last_season_netrtg', get_last_season_NETRTG, home_team, date_str)\n",
    "    try_feature('away_last_season_netrtg', get_last_season_NETRTG, away_team, date_str)\n",
    "    try_feature('home_last_season_oreb_pct', get_last_season_OREB_PCT, home_team, date_str)\n",
    "    try_feature('away_last_season_oreb_pct', get_last_season_OREB_PCT, away_team, date_str)\n",
    "    try_feature('home_last_season_efg_pct', FourFactors_ledger.get_last_season_EFG_PCT, home_team, date_str)\n",
    "    try_feature('away_last_season_efg_pct', FourFactors_ledger.get_last_season_EFG_PCT, away_team, date_str)\n",
    "    try_feature('home_last_season_tov_pct', FourFactors_ledger.get_last_season_TMV_TOV_PCT, home_team, date_str)\n",
    "    try_feature('away_last_season_tov_pct', FourFactors_ledger.get_last_season_TMV_TOV_PCT, away_team, date_str)\n",
    "    try_feature('home_last_season_ft_rate', get_last_season_FT_RATE, home_team, date_str)\n",
    "    try_feature('away_last_season_ft_rate', get_last_season_FT_RATE, away_team, date_str)\n",
    "\n",
    "    try_feature('home_netrtg_diff_prev_season', get_netrtg_diff_prev_season, home_team, season, date_str)\n",
    "    try_feature('away_netrtg_diff_prev_season', get_netrtg_diff_prev_season, away_team, season, date_str)\n",
    "    try_feature('home_game_number', get_game_number, home_team, season, date_str)\n",
    "    try_feature('away_game_number', get_game_number, away_team, season, date_str)\n",
    "\n",
    "    # ---------- Roster change features (8) ----------\n",
    "    prev_season = get_previous_season(season)\n",
    "    if prev_season:\n",
    "        timeline_curr = build_team_roster_timeline(season) # Should be from cache\n",
    "        prev_season = get_previous_season(season) \n",
    "        timeline_prev = build_team_roster_timeline(prev_season) # Should be from cache\n",
    "        try_feature('home_ppg_diff_prev_season', getTeamPPGRosterChange_on_date, home_team, date, season, prev_season, timeline_curr, timeline_prev)\n",
    "        try_feature('away_ppg_diff_prev_season', getTeamPPGRosterChange_on_date, away_team, date, season, prev_season, timeline_curr, timeline_prev)\n",
    "        try_feature('home_ast_tov_diff_prev_season', getTeamAstTovRosterChange_on_date, home_team, date, season, prev_season, timeline_curr, timeline_prev)\n",
    "        try_feature('away_ast_tov_diff_prev_season', getTeamAstTovRosterChange_on_date, away_team, date, season, prev_season, timeline_curr, timeline_prev)\n",
    "        try_feature('home_def_rating_diff_prev_season', getTeamStocksDREBRosterChange, home_team, date, season, prev_season, timeline_curr, timeline_prev)\n",
    "        try_feature('away_def_rating_diff_prev_season', getTeamStocksDREBRosterChange, away_team, date, season, prev_season, timeline_curr, timeline_prev)\n",
    "        try_feature('home_usg_rate_lost_prev_season', getTeamTotalMinutesLost_on_date, home_team, date, season, prev_season, timeline_curr, timeline_prev)\n",
    "        try_feature('away_usg_rate_lost_prev_season', getTeamTotalMinutesLost_on_date, away_team, date, season, prev_season, timeline_curr, timeline_prev)\n",
    "    else:\n",
    "        for k in [\n",
    "            'home_ppg_diff_prev_season','away_ppg_diff_prev_season',\n",
    "            'home_ast_tov_diff_prev_season','away_ast_tov_diff_prev_season',\n",
    "            'home_def_rating_diff_prev_season','away_def_rating_diff_prev_season',\n",
    "            'home_usg_rate_lost_prev_season','away_usg_rate_lost_prev_season'\n",
    "        ]:\n",
    "            features[k] = np.nan\n",
    "            feature_times[k] = 0.0\n",
    "            print(f\"⏱  {k:35s} {0.0:7.4f}s\")\n",
    "\n",
    "\n",
    "     # (Optional) print a short timing summary\n",
    "    print(f\"\\n✅ Finished features for {home_team} vs {away_team} on {date_str} ({season})\")\n",
    "    slow = sorted(feature_times.items(), key=lambda x: -x[1])[:5]\n",
    "    print(f\"⏱  Top slow features -> {slow}\\n\", flush=True)\n",
    "\n",
    "    # ---------- per-game FULL feature summary (toggle via env) ----------\n",
    "    import os, math\n",
    "    if os.getenv(\"SHOW_FEATURE_SUMMARY\", \"1\") == \"1\":\n",
    "        # Match your print_full_features_* style\n",
    "        precision = int(os.getenv(\"FEATURE_PRINT_PRECISION\", \"6\"))\n",
    "        sort_keys = os.getenv(\"FEATURE_PRINT_SORT_KEYS\", \"1\") == \"1\"\n",
    "\n",
    "        def _fmt(v):\n",
    "            try:\n",
    "                if v is None:\n",
    "                    return \"None\"\n",
    "                # numpy / float handling with NaN guard\n",
    "                f = float(v)\n",
    "                return \"nan\" if math.isnan(f) else f\"{f:.{precision}g}\"\n",
    "            except Exception:\n",
    "                return str(v)\n",
    "\n",
    "        print(f\"📊 feature summary — {away_team} @ {home_team} on {date_str} ({season})\")\n",
    "        keys = sorted(features.keys()) if sort_keys else list(features.keys())\n",
    "        for k in keys:\n",
    "            print(f\"{k}: {_fmt(features.get(k))}\")\n",
    "        print(\"— end of feature summary —\\n\")\n",
    "\n",
    "        # ========== PRIORS SNAPSHOT (all features your functions use) ==========\n",
    "        try:\n",
    "            dt = datetime.strptime(date_str, \"%m/%d/%Y\")\n",
    "            home_id = stats_getter.get_team_id(home_team)\n",
    "            away_id = stats_getter.get_team_id(away_team)\n",
    "            if home_id is None or away_id is None:\n",
    "                print(\"⚠️  Could not resolve TEAM_ID(s) for priors\")\n",
    "            else:\n",
    "                # -----------------------\n",
    "                # helpers\n",
    "                # -----------------------\n",
    "                def _fmt(x):\n",
    "                    try:\n",
    "                        import math\n",
    "                        return \"nan\" if x is None or (isinstance(x, float) and math.isnan(x)) else f\"{float(x):.6f}\"\n",
    "                    except Exception:\n",
    "                        return \"nan\"              \n",
    "                # -----------------------\n",
    "                # ADVANCED priors\n",
    "                # -----------------------\n",
    "                adv_away = {\n",
    "                    \"NET_RATING\": advanced_ledger.get_prior_net_rating(away_season, away_id, dt),\n",
    "                    \"EFG_PCT\":    advanced_ledger.get_prior_efg_pct(away_season, away_id, dt),\n",
    "                    \"TM_TOV_PCT\": advanced_ledger.get_prior_tm_tov_pct(away_season, away_id, dt),\n",
    "                    \"OREB_PCT\":   advanced_ledger.get_prior_oreb_pct(away_season, away_id, dt),\n",
    "                    \"DREB_PCT\":   advanced_ledger.get_prior_dreb_pct(away_season, away_id, dt),\n",
    "                    \"PACE\":       advanced_ledger.get_prior_pace(away_season, away_id, dt),\n",
    "                }\n",
    "                adv_home = {\n",
    "                    \"NET_RATING\": advanced_ledger.get_prior_net_rating(home_season, home_id, dt),\n",
    "                    \"EFG_PCT\":    advanced_ledger.get_prior_efg_pct(home_season, home_id, dt),\n",
    "                    \"TM_TOV_PCT\": advanced_ledger.get_prior_tm_tov_pct(home_season, home_id, dt),\n",
    "                    \"OREB_PCT\":   advanced_ledger.get_prior_oreb_pct(home_season, home_id, dt),\n",
    "                    \"DREB_PCT\":   advanced_ledger.get_prior_dreb_pct(home_season, home_id, dt),\n",
    "                    \"PACE\":       advanced_ledger.get_prior_pace(home_season, home_id, dt),\n",
    "                }\n",
    "                print(\"📊 Advanced priors (through previous day):\")\n",
    "                print(f\"  {away_team:<25} NETRTG {_fmt(adv_away['NET_RATING'])}  \"\n",
    "                    f\"EFG% {_fmt(adv_away['EFG_PCT'])}  TOV% {_fmt(adv_away['TM_TOV_PCT'])}  \"\n",
    "                    f\"OREB% {_fmt(adv_away['OREB_PCT'])}  DREB% {_fmt(adv_away['DREB_PCT'])}  \"\n",
    "                    f\"PACE {_fmt(adv_away['PACE'])}\")\n",
    "                print(f\"  {home_team:<25} NETRTG {_fmt(adv_home['NET_RATING'])}  \"\n",
    "                    f\"EFG% {_fmt(adv_home['EFG_PCT'])}  TOV% {_fmt(adv_home['TM_TOV_PCT'])}  \"\n",
    "                    f\"OREB% {_fmt(adv_home['OREB_PCT'])}  DREB% {_fmt(adv_home['DREB_PCT'])}  \"\n",
    "                    f\"PACE {_fmt(adv_home['PACE'])}\")\n",
    "\n",
    "                # -----------------------\n",
    "                # Four Factors priors\n",
    "                # -----------------------\n",
    "                ff_away = {\n",
    "                    \"EFG_PCT\":   FourFactors_ledger.get_prior_efg_pct(away_season, away_id, dt),\n",
    "                    \"FTA_RATE\":  FourFactors_ledger.get_prior_fta_rate(away_season, away_id, dt),\n",
    "                    \"TM_TOV_PCT\":FourFactors_ledger.get_prior_tm_tov_pct(away_season, away_id, dt),\n",
    "                    \"OREB_PCT\":  FourFactors_ledger.get_prior_oreb_pct(away_season, away_id, dt),\n",
    "                }\n",
    "                ff_home = {\n",
    "                    \"EFG_PCT\":   FourFactors_ledger.get_prior_efg_pct(home_season, home_id, dt),\n",
    "                    \"FTA_RATE\":  FourFactors_ledger.get_prior_fta_rate(home_season, home_id, dt),\n",
    "                    \"TM_TOV_PCT\":FourFactors_ledger.get_prior_tm_tov_pct(home_season, home_id, dt),\n",
    "                    \"OREB_PCT\":  FourFactors_ledger.get_prior_oreb_pct(home_season, home_id, dt),\n",
    "                }\n",
    "                print(\"🧮 Four Factors priors (through previous day):\")\n",
    "                print(f\"  {away_team:<25} EFG% {_fmt(ff_away['EFG_PCT'])}  FTA_RATE {_fmt(ff_away['FTA_RATE'])}  \"\n",
    "                    f\"TOV% {_fmt(ff_away['TM_TOV_PCT'])}  OREB% {_fmt(ff_away['OREB_PCT'])}\")\n",
    "                print(f\"  {home_team:<25} EFG% {_fmt(ff_home['EFG_PCT'])}  FTA_RATE {_fmt(ff_home['FTA_RATE'])}  \"\n",
    "                    f\"TOV% {_fmt(ff_home['TM_TOV_PCT'])}  OREB% {_fmt(ff_home['OREB_PCT'])}\")\n",
    "\n",
    "                # -----------------------\n",
    "                # Misc priors\n",
    "                # -----------------------\n",
    "                misc_away = {\n",
    "                    \"PTS_OFF_TOV\":   misc_ledger.get_prior_pts_off_tov(away_season, away_id, dt),\n",
    "                    \"PTS_FB\":        misc_ledger.get_prior_pts_fb(away_season, away_id, dt),\n",
    "                    \"PTS_2ND_CHANCE\":misc_ledger.get_prior_pts_2nd_chance(away_season, away_id, dt),\n",
    "                }\n",
    "                misc_home = {\n",
    "                    \"PTS_OFF_TOV\":   misc_ledger.get_prior_pts_off_tov(home_season, home_id, dt),\n",
    "                    \"PTS_FB\":        misc_ledger.get_prior_pts_fb(home_season, home_id, dt),\n",
    "                    \"PTS_2ND_CHANCE\":misc_ledger.get_prior_pts_2nd_chance(home_season, home_id, dt),\n",
    "                }\n",
    "                print(\"🧱 Misc priors (per-game, through previous day):\")\n",
    "                print(f\"  {away_team:<25} PTS_OFF_TOV {_fmt(misc_away['PTS_OFF_TOV'])}  \"\n",
    "                    f\"PTS_FB {_fmt(misc_away['PTS_FB'])}  \"\n",
    "                    f\"PTS_2ND_CHANCE {_fmt(misc_away['PTS_2ND_CHANCE'])}\")\n",
    "                print(f\"  {home_team:<25} PTS_OFF_TOV {_fmt(misc_home['PTS_OFF_TOV'])}  \"\n",
    "                    f\"PTS_FB {_fmt(misc_home['PTS_FB'])}  \"\n",
    "                    f\"PTS_2ND_CHANCE {_fmt(misc_home['PTS_2ND_CHANCE'])}\")\n",
    "\n",
    "                # -----------------------\n",
    "                # Hustle priors (DEFLECTIONS/SCREEN_ASSISTS from ledger; STOCKS from league log)\n",
    "                # -----------------------\n",
    "                hustle_away = {\n",
    "                    \"DEFLECTIONS\":    hustle_ledger.get_prior_deflections_pg(away_season, away_id, dt),\n",
    "                    \"SCREEN_ASSISTS\": hustle_ledger.get_prior_screen_assists_pg(away_season, away_id, dt),\n",
    "                    \"STOCKS\":         features_loader_copy._stocks_prior_pg(away_season, away_id, dt),\n",
    "                }\n",
    "                hustle_home = {\n",
    "                    \"DEFLECTIONS\":    hustle_ledger.get_prior_deflections_pg(home_season, home_id, dt),\n",
    "                    \"SCREEN_ASSISTS\": hustle_ledger.get_prior_screen_assists_pg(home_season, home_id, dt),\n",
    "                    \"STOCKS\":         features_loader_copy._stocks_prior_pg(home_season, home_id, dt),\n",
    "                }\n",
    "                print(\"🧹 Hustle priors (per-game, through previous day):\")\n",
    "                print(f\"  {away_team:<25} DEFLECTIONS {_fmt(hustle_away['DEFLECTIONS'])}  \"\n",
    "                    f\"SCREEN_AST {_fmt(hustle_away['SCREEN_ASSISTS'])}  \"\n",
    "                    f\"STOCKS {_fmt(hustle_away['STOCKS'])}\")\n",
    "                print(f\"  {home_team:<25} DEFLECTIONS {_fmt(hustle_home['DEFLECTIONS'])}  \"\n",
    "                    f\"SCREEN_AST {_fmt(hustle_home['SCREEN_ASSISTS'])}  \"\n",
    "                    f\"STOCKS {_fmt(hustle_home['STOCKS'])}\")\n",
    "        except Exception as e:\n",
    "            print(f\"(Priors print skipped: {e})\")\n",
    "        # =====================================================================\n",
    "    return features\n",
    "\n",
    "\n",
    "def get_team_games_in_season(team_name, season):\n",
    "    \"\"\"Get all games for a specific team in a season\"\"\"\n",
    "    try:\n",
    "        # Try to get from training_set.csv first\n",
    "        df = pd.read_csv('training_set.csv')\n",
    "        df_season = df[df['season'] == season]\n",
    "        \n",
    "        # Filter games where this team played (either home or away)\n",
    "        team_games = df_season[\n",
    "            (df_season['home_team'] == team_name) | \n",
    "            (df_season['away_team'] == team_name)\n",
    "        ].copy()\n",
    "        \n",
    "        return team_games\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error getting team games: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Note: Roster change functions are imported from features_loader_copy.py\n",
    "\n",
    "\n",
    "# Note: Roster change functions are imported from features_loader_copy.py\n",
    "\n",
    "\n",
    "def load_features_with_recovery(start_season=None):\n",
    "    \"\"\"Load features with ability to resume from a specific season\"\"\"\n",
    "    seasons = ['2015-16', '2016-17', '2017-18', '2018-19', '2019-20', \n",
    "               '2020-21', '2021-22', '2022-23', '2023-24', '2024-25']\n",
    "    \n",
    "    if start_season:\n",
    "        start_idx = seasons.index(start_season)\n",
    "        seasons = seasons[start_idx:]\n",
    "    \n",
    "    # Check if temp file exists\n",
    "    temp_file = 'nba_features_2015_2025.csv.temp'\n",
    "    if os.path.exists(temp_file):\n",
    "        print(f\"Found existing temp file. Loading previous progress...\")\n",
    "        existing_df = pd.read_csv(temp_file)\n",
    "        processed_seasons = existing_df['season'].unique()\n",
    "        seasons = [s for s in seasons if s not in processed_seasons]\n",
    "        print(f\"Resuming from seasons: {seasons}\")\n",
    "    \n",
    "    return load_all_features(seasons)\n",
    "\n",
    "def get_adaptive_delay(operation_type='default', attempt_number=1):\n",
    "    \"\"\"\n",
    "    Calculate delay based on operation type and retry attempts\n",
    "    \n",
    "    operation_type: 'team_change', 'endpoint_change', 'same_endpoint', 'minor'\n",
    "    attempt_number: Number of attempts (increases delay exponentially on retries)\n",
    "    \"\"\"\n",
    "    base_delays = {\n",
    "        'team_change': 3.0,      # Between different teams\n",
    "        'endpoint_change': 2.5,   # Between different stat types\n",
    "        'same_endpoint': 1.0,     # Same endpoint, different parameters\n",
    "        'minor': 0.5             # Minor operations\n",
    "    }\n",
    "    \n",
    "    base = base_delays.get(operation_type, 1.0)\n",
    "    \n",
    "    # Time of day adjustment\n",
    "    hour = datetime.now().hour\n",
    "    if 9 <= hour <= 17:\n",
    "        base *= 1.2\n",
    "    \n",
    "    # Exponential backoff for retries\n",
    "    if attempt_number > 1:\n",
    "        base *= (1.5 ** (attempt_number - 1))\n",
    "    \n",
    "    # Add randomness\n",
    "    final_delay = base + random.uniform(0, base * 0.5)\n",
    "    \n",
    "    return final_delay\n",
    "\n",
    "def fix_dates_in_training_set(csv_file='training_set.csv', out_file=None):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    # Convert 'date' to datetime, then to MM/DD/YYYY\n",
    "    df['date'] = pd.to_datetime(df['date']).dt.strftime(\"%m/%d/%Y\")\n",
    "    # Save back to file\n",
    "    if out_file is None:\n",
    "        out_file = csv_file  # overwrite\n",
    "    df.to_csv(out_file, index=False)\n",
    "    print(f\"Dates fixed and saved to {out_file}\")\n",
    "\n",
    "def load_features_for_window(season: str,\n",
    "                             start_date: str,\n",
    "                             end_date: str,\n",
    "                             output_file: str = \"nba_features_subset.csv\",\n",
    "                             disable_sleep: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load features only for games in [start_date, end_date] (MM/DD/YYYY) for a single season,\n",
    "    writing incrementally to disk. Builds the advanced ledger **as games pass**:\n",
    "    after computing features for a game, we append that game's 2-row TEAM table.\n",
    "    \"\"\"\n",
    "    if disable_sleep:\n",
    "        globals()['get_adaptive_delay'] = lambda *a, **k: 0.0\n",
    "\n",
    "    df_games = get_season_games(season).copy()\n",
    "    if df_games.empty:\n",
    "        print(f\"No games found for season {season}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    df_games['date'] = pd.to_datetime(df_games['date'], format=\"%m/%d/%Y\", errors='coerce')\n",
    "    start = pd.to_datetime(start_date, format=\"%m/%d/%Y\")\n",
    "    end   = pd.to_datetime(end_date,   format=\"%m/%d/%Y\")\n",
    "    df_games = df_games[(df_games['date'] >= start) & (df_games['date'] <= end)]\n",
    "    df_games = df_games.sort_values('date').reset_index(drop=True)\n",
    "\n",
    "    if df_games.empty:\n",
    "        print(f\"No games in window {start_date}–{end_date} for {season}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    for i, game in df_games.iterrows():\n",
    "        dstr = game['date'].strftime(\"%m/%d/%Y\")\n",
    "        home = game['home_team']; away = game['away_team']\n",
    "        try:\n",
    "            feats = calculate_game_features(\n",
    "                home_team=home, away_team=away, date=dstr, season=season\n",
    "            )\n",
    "            # Base info\n",
    "            feats['date'] = dstr\n",
    "            feats['home_team'] = home\n",
    "            feats['away_team'] = away\n",
    "            feats['season'] = season\n",
    "            for col in ['home_money_line','away_money_line','home_spread','away_spread','home_score','away_score']:\n",
    "                if col in game.index:\n",
    "                    feats[col] = game[col]\n",
    "            rows.append(feats)\n",
    "\n",
    "            # occasional save\n",
    "            if (i + 1) % 10 == 0:\n",
    "                pd.DataFrame(rows).to_csv(output_file, index=False)\n",
    "                print(f\"Saved progress: {i+1}/{len(df_games)} games -> {output_file}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Error: {home} vs {away} on {dstr}: {e}\")\n",
    "\n",
    "    df_out = pd.DataFrame(rows)\n",
    "    df_out.to_csv(output_file, index=False)\n",
    "    print(f\"✅ Wrote {len(df_out)} games to {output_file}\")\n",
    "    return df_out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(get_above_break_3pt_rate(\"Los Angeles Lakers\", \"Dallas Mavericks\", \"2015-16\", \"2015-16\", \"11/01/2015\"))\n",
    "\n",
    "\n",
    "# find the first game date in 2015-16\n",
    "\n",
    "#stats_cache.clear_cache()\n",
    "\n",
    "df = get_season_games(\"2015-16\").copy()\n",
    "df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%m/%d/%Y\", errors=\"coerce\")\n",
    "first_date = df[\"date\"].min()\n",
    "start_str = first_date.strftime(\"%m/%d/%Y\")\n",
    "end_str   = (first_date + timedelta(days=30)).strftime(\"%m/%d/%Y\")\n",
    "\n",
    "#print(f\"Window: {start_str} → {end_str}\")\n",
    "\n",
    "# run the loader\n",
    "#_ = build_dataset_for_window(start_date=start_str, end_date=end_str, seasons=(\"2015-16\",),  output_file=f\"nba_features_2015-16_{start_str.replace('/','-')}_to_{end_str.replace('/','-')}.csv\", save_every=1)\n",
    "\n",
    "\n",
    "\n",
    "#stats_cache.clear_cache()\n",
    "\n",
    "# ---- benchmarking helpers (paste near the bottom) ----\n",
    "import io, time\n",
    "from contextlib import contextmanager, redirect_stdout\n",
    "import numpy as np\n",
    "\n",
    "@contextmanager\n",
    "def muted_stdout(enabled=True):\n",
    "    if not enabled:\n",
    "        yield\n",
    "        return\n",
    "    buf = io.StringIO()\n",
    "    with redirect_stdout(buf):\n",
    "        yield\n",
    "\n",
    "def benchmark_games(season: str,\n",
    "                    start: str = None,   # \"MM/DD/YYYY\"\n",
    "                    end: str   = None,   # \"MM/DD/YYYY\"\n",
    "                    limit: int = None,\n",
    "                    quiet: bool = True,\n",
    "                    disable_sleep: bool = True):\n",
    "    \"\"\"Measure how fast your loader computes features per game.\"\"\"\n",
    "    if disable_sleep:\n",
    "        # zero inter-game delay for this process\n",
    "        globals()['get_adaptive_delay'] = lambda *a, **k: 0.0\n",
    "\n",
    "    df = get_season_games(season).copy()\n",
    "    df['date'] = pd.to_datetime(df['date'], format=\"%m/%d/%Y\", errors='coerce')\n",
    "    if start: df = df[df['date'] >= pd.to_datetime(start)]\n",
    "    if end:   df = df[df['date'] <= pd.to_datetime(end)]\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    if limit: df = df.head(limit)\n",
    "\n",
    "    per_game_secs, per_game_calls = [], []\n",
    "    t0 = time.perf_counter()\n",
    "    with muted_stdout(quiet):\n",
    "        for _, g in df.iterrows():\n",
    "            dstr = g['date'].strftime(\"%m/%d/%Y\")\n",
    "            t1 = time.perf_counter()\n",
    "            _ = calculate_game_features(g['home_team'], g['away_team'], dstr, season)\n",
    "            per_game_secs.append(time.perf_counter() - t1)\n",
    "            # how many network calls were made this game\n",
    "            per_game_calls.append(len(get_api_log()))\n",
    "    total = time.perf_counter() - t0\n",
    "\n",
    "    arr = np.array(per_game_secs)\n",
    "    print(\n",
    "        f\"Games: {len(arr)} | Total: {total:.2f}s | \"\n",
    "        f\"mean/game: {arr.mean():.2f}s | median: {np.median(arr):.2f}s | \"\n",
    "        f\"p95: {np.percentile(arr,95):.2f}s | API calls/game (mean): {np.mean(per_game_calls):.1f}\"\n",
    "    )\n",
    "# ---- benchmarking helpers (paste near the bottom) ----\n",
    "import io, time\n",
    "from contextlib import contextmanager, redirect_stdout\n",
    "import numpy as np\n",
    "\n",
    "@contextmanager\n",
    "def muted_stdout(enabled=True):\n",
    "    if not enabled:\n",
    "        yield\n",
    "        return\n",
    "    buf = io.StringIO()\n",
    "    with redirect_stdout(buf):\n",
    "        yield\n",
    "\n",
    "def benchmark_games(season: str,\n",
    "                    start: str = None,   # \"MM/DD/YYYY\"\n",
    "                    end: str   = None,   # \"MM/DD/YYYY\"\n",
    "                    limit: int = None,\n",
    "                    quiet: bool = True,\n",
    "                    disable_sleep: bool = True):\n",
    "    \"\"\"Measure how fast your loader computes features per game.\"\"\"\n",
    "    if disable_sleep:\n",
    "        # zero inter-game delay for this process\n",
    "        globals()['get_adaptive_delay'] = lambda *a, **k: 0.0\n",
    "\n",
    "    df = get_season_games(season).copy()\n",
    "    df['date'] = pd.to_datetime(df['date'], format=\"%m/%d/%Y\", errors='coerce')\n",
    "    if start: df = df[df['date'] >= pd.to_datetime(start)]\n",
    "    if end:   df = df[df['date'] <= pd.to_datetime(end)]\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    if limit: df = df.head(limit)\n",
    "\n",
    "    per_game_secs, per_game_calls = [], []\n",
    "    t0 = time.perf_counter()\n",
    "    with muted_stdout(quiet):\n",
    "        for _, g in df.iterrows():\n",
    "            dstr = g['date'].strftime(\"%m/%d/%Y\")\n",
    "            t1 = time.perf_counter()\n",
    "            _ = calculate_game_features(g['home_team'], g['away_team'], dstr, season)\n",
    "            per_game_secs.append(time.perf_counter() - t1)\n",
    "            # how many network calls were made this game\n",
    "            per_game_calls.append(len(get_api_log()))\n",
    "    total = time.perf_counter() - t0\n",
    "\n",
    "    arr = np.array(per_game_secs)\n",
    "    print(\n",
    "        f\"Games: {len(arr)} | Total: {total:.2f}s | \"\n",
    "        f\"mean/game: {arr.mean():.2f}s | median: {np.median(arr):.2f}s | \"\n",
    "        f\"p95: {np.percentile(arr,95):.2f}s | API calls/game (mean): {np.mean(per_game_calls):.1f}\"\n",
    "    )\n",
    "\n",
    "# ⚠️ Run this in a fresh cell to clear caches across the project.\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def clear_all_caches(\n",
    "    endpoints=(\n",
    "        # http/json endpoints you use via stats_cache\n",
    "        \"LeagueGameLog\",\n",
    "        \"TeamGameLog\",\n",
    "        \"LeagueDashTeamStats\",\n",
    "        \"LeagueHustleTeamStats\",\n",
    "        \"BoxScoreAdvancedV2\",\n",
    "        \"GameInfoFrankenLog\",\n",
    "    ),\n",
    "    also_delete_parquet=True,   # delete local ledger parquet files if present\n",
    "):\n",
    "    # 1) stats_cache memory + disk\n",
    "    try:\n",
    "        from cache_manager import stats_cache\n",
    "        print(\"→ clearing stats_cache in-memory …\")\n",
    "        stats_cache.clear_memory()\n",
    "\n",
    "        for key in endpoints:\n",
    "            try:\n",
    "                print(f\"→ clearing disk cache for: {key}\")\n",
    "                stats_cache.clear_disk(key)\n",
    "            except Exception as e:\n",
    "                print(f\"   (skip {key} clear_disk: {e})\")\n",
    "            try:\n",
    "                stats_cache.purge_empty_dfs(key)\n",
    "            except Exception as e:\n",
    "                print(f\"   (skip {key} purge_empty_dfs: {e})\")\n",
    "    except Exception as e:\n",
    "        print(f\"(stats_cache not available: {e})\")\n",
    "\n",
    "    # 2) clear any lru_cache’d helpers (safe no-ops if not lru_cache)\n",
    "    def _clear_if_lru(fn):\n",
    "        try:\n",
    "            fn.cache_clear()\n",
    "            print(f\"→ lru_cache cleared: {fn.__name__}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    try:\n",
    "        # common fetchers\n",
    "        from stats_getter import (\n",
    "            get_league_game_log,\n",
    "            getLeagueDashTeamStats,\n",
    "            getLeagueHustleTeamStats,\n",
    "            get_team_id,\n",
    "        )\n",
    "        for f in (get_league_game_log, getLeagueDashTeamStats, getLeagueHustleTeamStats, get_team_id):\n",
    "            _clear_if_lru(f)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        # your first-game helpers (if decorated with lru_cache)\n",
    "        from advanced_first_game import _prev_season_adv_value, _prev_season_poss_pg\n",
    "        for f in (_prev_season_adv_value, _prev_season_poss_pg):\n",
    "            _clear_if_lru(f)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 3) optionally remove local parquet ledgers (advanced / hustle)\n",
    "    if also_delete_parquet:\n",
    "        for pat in (\"advanced_*.parquet\", \"hustle_*.parquet\"):\n",
    "            cache_dir = Path(\"cache\")\n",
    "            if cache_dir.exists():\n",
    "                for p in cache_dir.glob(pat):\n",
    "                    try:\n",
    "                        p.unlink()\n",
    "                        print(f\"→ deleted {p}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"   (could not delete {p}: {e})\")\n",
    "\n",
    "    print(\"✅ cache clear complete\")\n",
    "\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "from stats_getter import (\n",
    "    get_team_id,\n",
    "    getLeagueDashTeamStats,\n",
    "    resolve_season_for_game_by_logs,\n",
    ")\n",
    "from advanced_ledger import (\n",
    "    get_prior_poss,             # prior getter used by the mixed function\n",
    "    _load_ledger              # internal; ok to import directly in your notebook\n",
    ")\n",
    "\n",
    "def debug_poss_for_game(home: str, away: str, date_str: str):\n",
    "    \"\"\"\n",
    "    Prints:\n",
    "      - Ledger row used for POSS_prior (per-team at date)\n",
    "      - Previous-season Advanced row (has POSS + GP), plus POSS/GP\n",
    "      - The values the mixed function would use for each side\n",
    "    \"\"\"\n",
    "    # 1) Make sure the single-game ledger rows exist\n",
    "    season_for_game = resolve_season_for_game_by_logs(date_str, home, away)\n",
    "    ensure_advanced_for_matchup(season_for_game, date_str, home, away)\n",
    "\n",
    "    day = pd.to_datetime(date_str).normalize()\n",
    "\n",
    "    def _show_ledger_row(team_name: str):\n",
    "        tid = get_team_id(team_name)\n",
    "        led = _load_ledger(season_for_game).copy()\n",
    "        led[\"GAME_DATE\"] = pd.to_datetime(led[\"GAME_DATE\"]).dt.normalize()\n",
    "        row = led[(led[\"TEAM_ID\"] == tid) & (led[\"GAME_DATE\"] == day)]\n",
    "\n",
    "        cols = [\n",
    "            \"SEASON\",\"GAME_ID\",\"GAME_DATE\",\"TEAM_ID\",\"TEAM_ABBREVIATION\",\n",
    "            \"PACE\",\"NET_RATING\",\"DREB_PCT\",\"OREB_PCT\",\"TM_TOV_PCT\",\"EFG_PCT\",\n",
    "            \"POSS_prior\",\"PACE_prior\",\"NET_RATING_prior\",\n",
    "            \"DREB_PCT_prior\",\"OREB_PCT_prior\",\"TM_TOV_PCT_prior\",\"EFG_PCT_prior\",\n",
    "        ]\n",
    "        print(f\"\\n[Ledger prior row] {team_name} on {date_str}  (season={season_for_game})\")\n",
    "        print(row[[c for c in cols if c in row.columns]])\n",
    "        return row\n",
    " \n",
    " # --- Sanity tests for \"first-game mixed\" features ---\n",
    "# Assumes your project modules are importable in this session.\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Project imports (adjust if your module paths differ)\n",
    "import stats_getter\n",
    "\n",
    "from advanced_first_game import _prev_season_adv_value, _prev_season_poss_pg\n",
    "\n",
    "# utils_cache.py (or a single notebook cell)\n",
    "\n",
    "from __future__ import annotations\n",
    "import sys, importlib, inspect, gc\n",
    "from pathlib import Path\n",
    "\n",
    "def _clear_all_lru_in_modules(limit_to_project=True, verbose=True) -> int:\n",
    "    \"\"\"\n",
    "    Find every callable in loaded modules that exposes .cache_clear()\n",
    "    (i.e., functools.lru_cache wrappers) and clear them.\n",
    "    If limit_to_project=True, only clears modules whose files live under cwd().\n",
    "    Returns number of caches cleared.\n",
    "    \"\"\"\n",
    "    root = Path.cwd().resolve()\n",
    "    cleared = 0\n",
    "\n",
    "    for mod in list(sys.modules.values()):\n",
    "        f = getattr(mod, \"__file__\", None)\n",
    "        if not f:\n",
    "            continue\n",
    "        if limit_to_project and root not in Path(f).resolve().parents:\n",
    "            continue\n",
    "\n",
    "        for name, obj in vars(mod).items():\n",
    "            # functions and methods decorated with lru_cache expose .cache_clear()\n",
    "            if callable(obj) and hasattr(obj, \"cache_clear\"):\n",
    "                try:\n",
    "                    obj.cache_clear()\n",
    "                    cleared += 1\n",
    "                    if verbose:\n",
    "                        print(f\" cleared LRU: {mod.__name__}.{name}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "    return cleared\n",
    "\n",
    "\n",
    "def _reset_ledgers_and_inprocess_memo(verbose=True):\n",
    "    \"\"\"\n",
    "    Your ledgers keep in-process memo DataFrames. Reset them.\n",
    "    \"\"\"\n",
    "    # hustle ledger\n",
    "    try:\n",
    "        import hustle_ledger\n",
    "        memo = getattr(hustle_ledger, \"_LEDGER_MEMO\", None)\n",
    "        if isinstance(memo, dict):\n",
    "            memo.clear()\n",
    "            if verbose:\n",
    "                print(\" reset hustle_ledger._LEDGER_MEMO\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # advanced ledger\n",
    "    try:\n",
    "        import advanced_ledger\n",
    "        memo = getattr(advanced_ledger, \"_LEDGER_MEMO\", None)\n",
    "        if isinstance(memo, dict):\n",
    "            memo.clear()\n",
    "            if verbose:\n",
    "                print(\" reset advanced_ledger._LEDGER_MEMO\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "\n",
    "def _delete_cache_files(also_parquet=True, verbose=True) -> int:\n",
    "    \"\"\"\n",
    "    Remove on-disk cache artifacts under ./.cache (your project uses this).\n",
    "    \"\"\"\n",
    "    cache_dir = Path(\".cache\")\n",
    "    if not cache_dir.exists():\n",
    "        return 0\n",
    "\n",
    "    patterns = []\n",
    "    if also_parquet:\n",
    "        # ledgers\n",
    "        patterns += [\"advanced_*.parquet\", \"hustle_*.parquet\"]\n",
    "    # if your stats cache drops files here, include them too:\n",
    "    patterns += [\"*.json\", \"*.pkl\", \"*.pickle\"]\n",
    "\n",
    "    deleted = 0\n",
    "    for pat in patterns:\n",
    "        for f in cache_dir.glob(pat):\n",
    "            try:\n",
    "                f.unlink()\n",
    "                deleted += 1\n",
    "                if verbose:\n",
    "                    print(f\" deleted: {f}\")\n",
    "            except IsADirectoryError:\n",
    "                pass\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # clean up any empty subfolders that might be left behind\n",
    "    for p in sorted(cache_dir.rglob(\"*\"), reverse=True):\n",
    "        if p.is_dir():\n",
    "            try:\n",
    "                next(p.iterdir())\n",
    "            except StopIteration:\n",
    "                try:\n",
    "                    p.rmdir()\n",
    "                    if verbose:\n",
    "                        print(f\" removed empty dir: {p}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "    return deleted\n",
    "\n",
    "\n",
    "def clear_all_caches_hard(*, reload_modules=False, verbose=True):\n",
    "    \"\"\"\n",
    "    One-button 'cold-start':\n",
    "      1) clear every lru_cache across your project (no manual list)\n",
    "      2) reset in-process memo dicts used by your ledgers\n",
    "      3) delete ledger parquet files (and common cache files) in ./.cache\n",
    "      4) clear your custom stats_cache if available\n",
    "      5) (optional) importlib.reload on your project modules\n",
    "\n",
    "    Use this right before timing expensive first-game calls.\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"—— Clearing LRU caches ——\")\n",
    "    n = _clear_all_lru_in_modules(limit_to_project=True, verbose=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"—— Resetting in-process ledgers ——\")\n",
    "    _reset_ledgers_and_inprocess_memo(verbose=verbose)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"—— Deleting on-disk cache files ——\")\n",
    "    deleted = _delete_cache_files(also_parquet=True, verbose=verbose)\n",
    "\n",
    "    # your app-level disk cache wrapper, if present\n",
    "    try:\n",
    "        from cache_manager import stats_cache\n",
    "        if hasattr(stats_cache, \"clear_all\"):\n",
    "            stats_cache.clear_all(also_delete_parquet=True)\n",
    "            if verbose:\n",
    "                print(\" cleared cache_manager.stats_cache\")\n",
    "        elif hasattr(stats_cache, \"clear\"):\n",
    "            stats_cache.clear()\n",
    "            if verbose:\n",
    "                print(\" cleared cache_manager.stats_cache (basic)\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if reload_modules:\n",
    "        if verbose:\n",
    "            print(\"—— Reloading project modules ——\")\n",
    "        for name in (\"stats_getter\", \"hustle_ledger\", \"advanced_ledger\", \"cache_manager\"):\n",
    "            if name in sys.modules:\n",
    "                try:\n",
    "                    importlib.reload(sys.modules[name])\n",
    "                    if verbose:\n",
    "                        print(f\" reloaded {name}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"✅ Done. Cleared {n} LRU caches, deleted {deleted} files.\")\n",
    "\n",
    "\n",
    "# (Optional) quick sanity helper to see if anything is still cached\n",
    "def print_any_cache_hits():\n",
    "    for mod in list(sys.modules.values()):\n",
    "        f = getattr(mod, \"__file__\", None)\n",
    "        if not f or Path.cwd().resolve() not in Path(f).resolve().parents:\n",
    "            continue\n",
    "        for name, obj in vars(mod).items():\n",
    "            if callable(obj) and hasattr(obj, \"cache_info\"):\n",
    "                try:\n",
    "                    info = obj.cache_info()  # type: ignore[attr-defined]\n",
    "                    if getattr(info, \"currsize\", 0):\n",
    "                        print(f\" cache non-empty: {mod.__name__}.{name} -> {info}\")\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "\n",
    "# --- usage ---\n",
    "# clear_all_caches_hard(also_delete_parquets=True, verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from stats_getter import get_league_game_log, get_team_id, resolve_season_for_game_by_logs\n",
    "from advanced_ledger import ensure_advanced_for_matchup, _load_ledger\n",
    "\n",
    "def _two_game_matchups(season: str, limit: int = 3):\n",
    "    \"\"\"\n",
    "    Return up to `limit` games where BOTH teams are on their 2nd game of the season.\n",
    "    Each item: dict(game_id, date_str, home_team, away_team)\n",
    "    \"\"\"\n",
    "    lg = get_league_game_log(season).copy()\n",
    "    lg[\"GAME_DATE\"] = pd.to_datetime(lg[\"GAME_DATE\"])\n",
    "    # per-team game index\n",
    "    lg = lg.sort_values([\"TEAM_ID\", \"GAME_DATE\", \"GAME_ID\"])\n",
    "    lg[\"GAME_NUM\"] = lg.groupby(\"TEAM_ID\").cumcount() + 1\n",
    "\n",
    "    # keep only rows that are a team's 2nd game\n",
    "    g2 = lg[lg[\"GAME_NUM\"] == 2]\n",
    "\n",
    "    out = []\n",
    "    # group by game id; only take those that have two rows and both are game #2\n",
    "    for gid, grp in g2.groupby(\"GAME_ID\"):\n",
    "        if grp.shape[0] != 2:\n",
    "            continue\n",
    "        r1, r2 = grp.iloc[0], grp.iloc[1]\n",
    "        # determine home/away by MATCHUP text\n",
    "        def is_home(row):\n",
    "            m = str(row.get(\"MATCHUP\", \"\"))\n",
    "            return (\" vs \" in m) or (\"vs.\" in m)\n",
    "        home_row = r1 if is_home(r1) else r2\n",
    "        away_row = r2 if is_home(r1) else r1\n",
    "        out.append(dict(\n",
    "            game_id=str(gid),\n",
    "            date_str=pd.to_datetime(home_row[\"GAME_DATE\"]).strftime(\"%m/%d/%Y\"),\n",
    "            home_team=str(home_row[\"TEAM_NAME\"]),\n",
    "            away_team=str(away_row[\"TEAM_NAME\"]),\n",
    "        ))\n",
    "        if len(out) >= limit:\n",
    "            break\n",
    "    return out\n",
    "\n",
    "def _assert_close(a, b, name, tol=1e-6):\n",
    "    if any([\n",
    "        a is None, b is None,\n",
    "        (isinstance(a, float) and math.isnan(a)),\n",
    "        (isinstance(b, float) and math.isnan(b)),\n",
    "    ]):\n",
    "        raise AssertionError(f\"{name}: NaN/None -> got {a} vs {b}\")\n",
    "    if abs(float(a) - float(b)) > tol:\n",
    "        raise AssertionError(f\"{name}: |{a}-{b}|={abs(float(a)-float(b))} > {tol}\")\n",
    "\n",
    "def _ledger_row_for(team_name: str, season_for_game: str, date_str: str):\n",
    "    \"\"\"Return the ledger row for (team, date), and the immediate previous row (game #1).\"\"\"\n",
    "    led = _load_ledger(season_for_game).copy()\n",
    "    led[\"GAME_DATE\"] = pd.to_datetime(led[\"GAME_DATE\"]).dt.normalize()\n",
    "    day = pd.to_datetime(date_str).normalize()\n",
    "    tid = get_team_id(team_name)\n",
    "    team_rows = led[led[\"TEAM_ID\"] == tid].sort_values(\"GAME_DATE\")\n",
    "    today_row = team_rows[team_rows[\"GAME_DATE\"] == day].tail(1)\n",
    "    prev_row  = team_rows[team_rows[\"GAME_DATE\"] <  day].tail(1)\n",
    "    return today_row, prev_row\n",
    "\n",
    "def inspect_pace_second_game(home_team: str, away_team: str, date_str: str, season: str, tol: float = 1e-6):\n",
    "    \"\"\"\n",
    "    Verify that for a true second game:\n",
    "      - ledger PACE_prior equals game-1 PACE for each team\n",
    "      - features['pace_ratio'] == home.PACE_prior / away.PACE_prior\n",
    "    \"\"\"\n",
    "    # pick the correct season label for the game by logs (safe if cross-year calendars)\n",
    "    season_for_game = resolve_season_for_game_by_logs(date_str, home_team, away_team)\n",
    "\n",
    "    # build only up to this date\n",
    "    ensure_advanced_for_matchup(season_for_game, date_str)\n",
    "\n",
    "    # ledger rows\n",
    "    h_today, h_prev = _ledger_row_for(home_team, season_for_game, date_str)\n",
    "    a_today, a_prev = _ledger_row_for(away_team, season_for_game, date_str)\n",
    "\n",
    "    if h_today.empty or a_today.empty or h_prev.empty or a_prev.empty:\n",
    "        raise RuntimeError(\"Missing ledger rows; are you sure this is both teams' 2nd game?\")\n",
    "\n",
    "    # extract numbers\n",
    "    h_prior = float(pd.to_numeric(h_today.iloc[0].get(\"PACE_prior\"), errors=\"coerce\"))\n",
    "    a_prior = float(pd.to_numeric(a_today.iloc[0].get(\"PACE_prior\"), errors=\"coerce\"))\n",
    "    h_g1_pace = float(pd.to_numeric(h_prev.iloc[0].get(\"PACE\"), errors=\"coerce\"))\n",
    "    a_g1_pace = float(pd.to_numeric(a_prev.iloc[0].get(\"PACE\"), errors=\"coerce\"))\n",
    "\n",
    "    # 1) priors equal game-1 values?\n",
    "    _assert_close(h_prior, h_g1_pace, f\"{home_team} PACE_prior == game1 PACE\", tol)\n",
    "    _assert_close(a_prior, a_g1_pace, f\"{away_team} PACE_prior == game1 PACE\", tol)\n",
    "\n",
    "    # 2) expected ratio from priors\n",
    "    exp_ratio = h_prior / a_prior if a_prior not in (0.0, None) and not math.isnan(a_prior) else float(\"nan\")\n",
    "\n",
    "    # 3) actual feature value\n",
    "    feats = calculate_game_features(home_team, away_team, date_str, season)\n",
    "    got_ratio = feats.get(\"pace_ratio\")\n",
    "\n",
    "    # 4) compare\n",
    "    _assert_close(got_ratio, exp_ratio, \"pace_ratio (from ledger priors)\", tol)\n",
    "\n",
    "    # pretty print\n",
    "    print(f\"\\n=== {season_for_game} Game #2 check on {date_str} ===\")\n",
    "    print(f\"Home: {home_team:25s} prior={h_prior:.3f} (game1 pace {h_g1_pace:.3f})\")\n",
    "    print(f\"Away: {away_team:25s} prior={a_prior:.3f} (game1 pace {a_g1_pace:.3f})\")\n",
    "    print(f\"Feature pace_ratio  = {float(got_ratio):.6f}\")\n",
    "    print(f\"Expected (priors)   = {float(exp_ratio):.6f}\")\n",
    "    print(\"✅ pace source = advanced ledger priors (matches).\")\n",
    "\n",
    "def test_some_second_games(season: str, limit: int = 3, tol: float = 1e-6):\n",
    "    \"\"\"\n",
    "    Auto-run the check on a few second-game matchups.\n",
    "    \"\"\"\n",
    "    picks = _two_game_matchups(season, limit=limit)\n",
    "    if not picks:\n",
    "        print(f\"No true 2nd-game matchups found for {season}.\")\n",
    "        return\n",
    "    for g in picks:\n",
    "        print(f\"\\n→ Testing {g['home_team']} vs {g['away_team']} on {g['date_str']} (GAME_ID {g['game_id']})\")\n",
    "        inspect_pace_second_game(g[\"home_team\"], g[\"away_team\"], g[\"date_str\"], season, tol)\n",
    "\n",
    "def print_advanced_priors_first_n_games_global(season: str = \"2018-19\", first_n: int = 20) -> None:\n",
    "    \"\"\"\n",
    "    For the first `first_n` *games* of `season` (league-wide), print only the\n",
    "    advanced *prior-to-game* values for both teams in each matchup.\n",
    "\n",
    "    For each team/metric, a source label shows whether the value came from:\n",
    "      - prev-season  (first game fallback), or\n",
    "      - ledger       (cumulative from BoxScoreAdvancedV2 rows)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from stats_getter import get_league_game_log\n",
    "    from advanced_ledger import (\n",
    "        ensure_advanced_for_game, _load_ledger,\n",
    "        get_prior_pace, get_prior_net_rating, get_prior_dreb_pct,\n",
    "        get_prior_oreb_pct, get_prior_poss, get_prior_tm_tov_pct, get_prior_efg_pct,\n",
    "    )\n",
    "\n",
    "    METRICS = [\n",
    "        (\"PACE\",       get_prior_pace),\n",
    "        (\"NET_RATING\", get_prior_net_rating),\n",
    "        (\"DREB_PCT\",   get_prior_dreb_pct),\n",
    "        (\"OREB_PCT\",   get_prior_oreb_pct),\n",
    "        (\"POSS\",       get_prior_poss),\n",
    "        (\"TM_TOV_PCT\", get_prior_tm_tov_pct),\n",
    "        (\"EFG_PCT\",    get_prior_efg_pct),\n",
    "    ]\n",
    "\n",
    "    # 1) League log → unique games in chronological order\n",
    "    log = get_league_game_log(season).copy()\n",
    "    log[\"GAME_DATE\"] = pd.to_datetime(log[\"GAME_DATE\"]).dt.normalize()\n",
    "    games = (\n",
    "        log[[\"GAME_ID\", \"GAME_DATE\"]]\n",
    "        .drop_duplicates()\n",
    "        .sort_values([\"GAME_DATE\", \"GAME_ID\"])\n",
    "        .head(int(first_n))\n",
    "    )\n",
    "    if games.empty:\n",
    "        print(f\"No games found for {season}.\"); return\n",
    "\n",
    "    # 2) Iterate games in order; for each, ensure ledger rows exist and priors are computed\n",
    "    for idx, grow in games.reset_index(drop=True).iterrows():\n",
    "        gid   = str(grow[\"GAME_ID\"]).zfill(10)\n",
    "        gdate = grow[\"GAME_DATE\"]\n",
    "\n",
    "        # Add this game’s advanced rows & recompute priors just for the two teams\n",
    "        ensure_advanced_for_game(season, gid)\n",
    "\n",
    "        # Reload ledger to read the computed *_prior values for this exact game row\n",
    "        ledger = _load_ledger(season)\n",
    "\n",
    "        # Pull the two teams for this GAME_ID from the league log (labels, home/away)\n",
    "        two = (\n",
    "            log.loc[log[\"GAME_ID\"].astype(str) == gid,\n",
    "                    [\"TEAM_ID\", \"TEAM_ABBREVIATION\", \"MATCHUP\"]]\n",
    "            .drop_duplicates()\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        date_str = gdate.strftime(\"%m/%d/%Y\")\n",
    "        matchup  = \" vs \".join([str(x) for x in two[\"TEAM_ABBREVIATION\"].tolist()]) if \"TEAM_ABBREVIATION\" in two else \"(unknown)\"\n",
    "        print(f\"\\n=== Game {idx+1}: {date_str} — GAME_ID {gid} — {matchup} ===\")\n",
    "\n",
    "        # 3) For each team in the game, print advanced priors + source (ledger vs prev-season)\n",
    "        for r in two.itertuples(index=False):\n",
    "            tid   = int(r.TEAM_ID)\n",
    "            team  = getattr(r, \"TEAM_ABBREVIATION\", str(tid))\n",
    "            mrow  = (ledger[\"TEAM_ID\"].astype(int) == tid) & (ledger[\"GAME_ID\"].astype(str) == gid)\n",
    "            if not mrow.any():\n",
    "                print(f\"  {team}: (ledger row missing)\"); continue\n",
    "\n",
    "            parts = []\n",
    "            for metric, getter in METRICS:\n",
    "                prior_col  = f\"{metric}_prior\"\n",
    "                ledger_v   = ledger.loc[mrow, prior_col].iloc[0] if prior_col in ledger.columns else float(\"nan\")\n",
    "                src_label  = \"ledger\" if pd.notna(ledger_v) else \"prev-season\"\n",
    "                val        = getter(season, tid, gdate)  # uses ledger; falls back to prev-season if needed\n",
    "                parts.append(f\"{metric}={float(val):.6g} [{src_label}]\")\n",
    "\n",
    "            print(f\"  {team}: \" + \", \".join(parts))\n",
    "\n",
    "def print_full_features_first_n_games_global(\n",
    "    n: int,\n",
    "    season: str = \"2024-25\",\n",
    "    precision: int = 6,\n",
    "    quiet: bool = False,\n",
    "    disable_sleep: bool = True,\n",
    "    sort_keys: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Print the full features for the first `n` league games of `season`\n",
    "    using `calculate_game_features(home_team, away_team, date, season)`.\n",
    "\n",
    "    - Processes games in strict chronological order.\n",
    "    - Prints every feature key with its numeric value.\n",
    "    - `quiet=True` mutes any verbose prints inside calculate_game_features.\n",
    "    - `disable_sleep=True` zeroes your adaptive delay helper for quicker runs.\n",
    "    - `precision` controls float formatting (sig figs via g-format).\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import math\n",
    "\n",
    "    # Optional: disable any internal sleeps to speed up the test run\n",
    "    if disable_sleep:\n",
    "        try:\n",
    "            globals()['get_adaptive_delay'] = lambda *a, **k: 0.0\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Minimal stdout muter so you can flip `quiet` on/off\n",
    "    try:\n",
    "        _ = muted_stdout  # if you already defined one elsewhere\n",
    "    except NameError:\n",
    "        from contextlib import contextmanager, redirect_stdout\n",
    "        import io\n",
    "        @contextmanager\n",
    "        def muted_stdout(enabled=True):\n",
    "            if not enabled:\n",
    "                yield\n",
    "                return\n",
    "            buf = io.StringIO()\n",
    "            with redirect_stdout(buf):\n",
    "                yield\n",
    "\n",
    "    # Pull schedule and take first n distinct games (league-wide)\n",
    "    try:\n",
    "        df = get_season_games(season).copy()\n",
    "    except NameError:\n",
    "        raise RuntimeError(\"get_season_games(season) not found in scope.\")\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"[{season}] No games found.\")\n",
    "        return\n",
    "\n",
    "    # Expecting columns: date (MM/DD/YYYY), home_team, away_team\n",
    "    df['date'] = pd.to_datetime(df['date'], format=\"%m/%d/%Y\", errors='coerce')\n",
    "    df = df.sort_values('date').reset_index(drop=True)\n",
    "    df = df.head(int(n))\n",
    "\n",
    "    # Pretty value formatter\n",
    "    def _fmt(v):\n",
    "        try:\n",
    "            # Treat numpy scalars like floats\n",
    "            if v is None:\n",
    "                return \"None\"\n",
    "            if isinstance(v, (int,)) and not isinstance(v, bool):\n",
    "                return str(v)\n",
    "            if isinstance(v, float) or (hasattr(v, \"dtype\") and str(getattr(v, \"dtype\", \"\")).startswith(\"float\")):\n",
    "                if math.isnan(v):\n",
    "                    return \"nan\"\n",
    "                return f\"{float(v):.{precision}g}\"\n",
    "            return str(v)\n",
    "        except Exception:\n",
    "            return str(v)\n",
    "\n",
    "    for i, g in df.iterrows():\n",
    "        d = g['date']\n",
    "        dstr = d.strftime(\"%m/%d/%Y\") if pd.notnull(d) else str(g['date'])\n",
    "        home = g['home_team']\n",
    "        away = g['away_team']\n",
    "\n",
    "        # Compute features for this matchup/date\n",
    "        with muted_stdout(quiet):\n",
    "            try:\n",
    "                feats = calculate_game_features(\n",
    "                    home_team=home,\n",
    "                    away_team=away,\n",
    "                    date=dstr,\n",
    "                    season=season\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"\\n#{i+1}  {season}  {dstr}:  {away} @ {home}\")\n",
    "                print(\"-\" * 60)\n",
    "                print(f\"ERROR running calculate_game_features: {e}\")\n",
    "                continue\n",
    "\n",
    "        print(f\"\\n#{i+1}  {season}  {dstr}:  {away} @ {home}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        keys = sorted(feats.keys()) if sort_keys else list(feats.keys())\n",
    "        for k in keys:\n",
    "            print(f\"{k}: {_fmt(feats[k])}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def _team_first_three_games(season: str, team_name: str):\n",
    "    \"\"\"Return (tid, df_team_first3) with columns GAME_ID (str), GAME_DATE (Timestamp).\"\"\"\n",
    "    lg = stats_getter.get_league_game_log(season).copy()\n",
    "    lg[\"GAME_DATE\"] = pd.to_datetime(lg[\"GAME_DATE\"])\n",
    "    tid = stats_getter.get_team_id(team_name)\n",
    "    if tid is None:\n",
    "        raise ValueError(f\"Unknown team: {team_name}\")\n",
    "    tlog = (lg[lg[\"TEAM_ID\"] == int(tid)]\n",
    "              .sort_values([\"GAME_DATE\", \"GAME_ID\"])\n",
    "              .head(3)[[\"GAME_ID\",\"GAME_DATE\"]]\n",
    "              .copy())\n",
    "    tlog[\"GAME_ID\"] = tlog[\"GAME_ID\"].astype(str).str.zfill(10)\n",
    "    if len(tlog) < 3:\n",
    "        raise RuntimeError(f\"{team_name} has <3 games in {season} log.\")\n",
    "    return int(tid), tlog.reset_index(drop=True)\n",
    "\n",
    "def prepare_first_two_and_show_ledger(season: str, team_name: str):\n",
    "    \"\"\"\n",
    "    Append only game #1 and #2 to the ledger, then print those ledger rows.\n",
    "    Returns (tid, g1_id, g2_id, g3_date) to use in the next step.\n",
    "    \"\"\"\n",
    "    tid, t3 = _team_first_three_games(season, team_name)\n",
    "    g1_id, g2_id = t3.loc[0, \"GAME_ID\"], t3.loc[1, \"GAME_ID\"]\n",
    "    g3_date = pd.to_datetime(t3.loc[2, \"GAME_DATE\"]).normalize()\n",
    "\n",
    "    # append first two games (idempotent)\n",
    "    append_adv_game(season, g1_id)\n",
    "    append_adv_game(season, g2_id)\n",
    "\n",
    "    # show ledger rows for those two games\n",
    "    led = _load_ledger(season).copy()\n",
    "    led[\"GAME_DATE\"] = pd.to_datetime(led[\"GAME_DATE\"]).dt.normalize()\n",
    "    rows = (led[(led[\"TEAM_ID\"].astype(int) == tid) &\n",
    "                (led[\"GAME_ID\"].astype(str).isin([g1_id, g2_id]))]\n",
    "            .sort_values([\"GAME_DATE\",\"GAME_ID\"]))\n",
    "    keep = [c for c in [\n",
    "        \"SEASON\",\"GAME_ID\",\"GAME_DATE\",\"TEAM_ID\",\"TEAM_ABBREVIATION\",\n",
    "        \"PACE\",\"NET_RATING\",\"DREB_PCT\",\"OREB_PCT\",\"TM_TOV_PCT\",\"EFG_PCT\"\n",
    "    ] if c in rows.columns]\n",
    "    print(\"\\n=== Ledger rows after appending G1 & G2 ===\")\n",
    "    print(rows[keep])\n",
    "    return tid, g1_id, g2_id, g3_date\n",
    "\n",
    "def inspect_third_game_windows(season: str, team_name: str, g3_date, N: int = 2,\n",
    "                               metrics=(\"OREB_PCT\",\"EFG_PCT\",\"TM_TOV_PCT\",\"PACE\",\"NET_RATING\")):\n",
    "    \"\"\"\n",
    "    Show the last-N valid values BEFORE the 3rd game's date for each metric.\n",
    "    This is exactly the data your recent-mean helper should average.\n",
    "    \"\"\"\n",
    "    tid = stats_getter.get_team_id(team_name)\n",
    "    led = _load_ledger(season).copy()\n",
    "    if led is None or led.empty:\n",
    "        raise RuntimeError(\"Ledger is empty.\")\n",
    "\n",
    "    led[\"GAME_DATE\"] = pd.to_datetime(led[\"GAME_DATE\"])\n",
    "    s = (led[led[\"TEAM_ID\"].astype(int) == int(tid)]\n",
    "           .sort_values([\"GAME_DATE\",\"GAME_ID\"])\n",
    "           .reset_index(drop=True))\n",
    "\n",
    "    print(f\"\\n=== Last {N} BEFORE {g3_date.strftime('%m/%d/%Y')} for {team_name} ===\")\n",
    "    out = {}\n",
    "    for m in metrics:\n",
    "        if m not in s.columns:\n",
    "            print(f\"{m}: (column missing)\"); continue\n",
    "        vals = pd.to_numeric(s.loc[s[\"GAME_DATE\"] < g3_date, m], errors=\"coerce\").dropna().tail(N)\n",
    "        out[m] = vals\n",
    "        print(f\"{m}:\")\n",
    "        print(vals.reset_index(drop=True))\n",
    "    return out\n",
    "\n",
    "def assert_third_game_ready(season: str, team_name: str, N: int = 2):\n",
    "    \"\"\"\n",
    "    Full check:\n",
    "      - append only the first two games\n",
    "      - verify each metric has N valid priors before game #3\n",
    "    \"\"\"\n",
    "    tid, g1, g2, g3_date = prepare_first_two_and_show_ledger(season, team_name)\n",
    "    windows = inspect_third_game_windows(season, team_name, g3_date, N=N)\n",
    "    # simple assertion: each tracked metric has N values\n",
    "    missing = [m for m,v in windows.items() if len(v) < N]\n",
    "    if missing:\n",
    "        raise AssertionError(f\"Not enough priors before game #3 for: {missing}\")\n",
    "    print(\"\\n✅ Third game has enough non-NaN priors for all tracked metrics.\")\n",
    "\n",
    "def time_features_with_team_priors_first_n_games_MUTATING(\n",
    "    n: int,\n",
    "    season: str = \"2024-25\",\n",
    "    precision: int = 6,\n",
    "    quiet: bool = False,\n",
    "    disable_sleep: bool = True,\n",
    "    return_df: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    For the first `n` league games of `season`, in strict chronological order:\n",
    "      1) Print/timestamp ONLY these calls:\n",
    "           - get_pace_diff(home, away, season, season, date_str)\n",
    "           - get_oreb_pct_relative(home, away, season, season, date_str)\n",
    "           - get_dreb_pct_relative(home, away, season, season, date_str)\n",
    "      2) Print HOME/AWAY team priors (running averages up to the day BEFORE the game)\n",
    "      3) **Append this game to the advanced ledger** (idempotent), so you can\n",
    "         inspect the true ledger rows afterward with show_team_advanced_ledger(...).\n",
    "\n",
    "    Assumptions:\n",
    "      - get_season_games(season) -> DataFrame with columns: date (MM/DD/YYYY), home_team, away_team\n",
    "      - stats_getter.get_team_id(name) exists\n",
    "      - stats_getter.get_league_game_log(season) exists and includes GAME_ID, GAME_DATE, TEAM_ID, TEAM_NAME/ABBREVIATION\n",
    "      - advanced_ledger exposes:\n",
    "            get_prior_pace, get_prior_oreb_pct, get_prior_dreb_pct, append_adv_game\n",
    "      - Your three feature functions are already defined in scope.\n",
    "    \"\"\"\n",
    "    import time, math\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "\n",
    "    # Optional: disable any internal sleeps your code might use\n",
    "    if disable_sleep:\n",
    "        try:\n",
    "            globals()['get_adaptive_delay'] = lambda *a, **k: 0.0\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    # Quiet helper\n",
    "    try:\n",
    "        _ = muted_stdout\n",
    "    except NameError:\n",
    "        from contextlib import contextmanager, redirect_stdout\n",
    "        import io\n",
    "        @contextmanager\n",
    "        def muted_stdout(enabled=True):\n",
    "            if not enabled:\n",
    "                yield\n",
    "                return\n",
    "            buf = io.StringIO()\n",
    "            with redirect_stdout(buf):\n",
    "                yield\n",
    "\n",
    "    def _fmt(x):\n",
    "        try:\n",
    "            if x is None: return \"None\"\n",
    "            xf = float(x)\n",
    "            if math.isnan(xf): return \"nan\"\n",
    "            return f\"{xf:.{precision}g}\"\n",
    "        except Exception:\n",
    "            return str(x)\n",
    "\n",
    "    # Imports you provide\n",
    "    from stats_getter import get_team_id, get_league_game_log\n",
    "    from advanced_ledger import get_prior_pace, get_prior_oreb_pct, get_prior_dreb_pct, append_adv_game\n",
    "\n",
    "    # Map (date, home, away) -> GAME_ID via league log\n",
    "    def _resolve_game_id(date_ts, home_name, away_name):\n",
    "        hid = get_team_id(home_name)\n",
    "        aid = get_team_id(away_name)\n",
    "        if hid is None or aid is None:\n",
    "            return None\n",
    "        # Filter league log by date (normalized) and team IDs, then find common GAME_ID\n",
    "        rows = league_log[\n",
    "            (league_log[\"_DATE\"] == pd.to_datetime(date_ts).normalize())\n",
    "            & (league_log[\"TEAM_ID\"].isin([hid, aid]))\n",
    "        ]\n",
    "        gids = rows[\"GAME_ID\"].dropna().unique().tolist()\n",
    "        if len(gids) == 1:\n",
    "            return str(gids[0])\n",
    "        # Fallback: if multiple (rare), pick the GAME_ID that has both teams\n",
    "        for gid in gids:\n",
    "            sub = league_log[league_log[\"GAME_ID\"] == gid]\n",
    "            if set(sub[\"TEAM_ID\"].unique()).issuperset({hid, aid}):\n",
    "                return str(gid)\n",
    "        return None\n",
    "\n",
    "    # Pull schedule and league log\n",
    "    try:\n",
    "        sched = get_season_games(season).copy()\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"get_season_games({season}) failed: {e}\")\n",
    "    if sched is None or sched.empty:\n",
    "        print(f\"[{season}] No games found.\")\n",
    "        return pd.DataFrame() if return_df else None\n",
    "\n",
    "    try:\n",
    "        league_log = get_league_game_log(season).copy()\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"get_league_game_log({season}) failed: {e}\")\n",
    "    if league_log is None or league_log.empty:\n",
    "        raise RuntimeError(f\"No league game log for season {season}\")\n",
    "\n",
    "    # Normalize times\n",
    "    sched[\"date\"] = pd.to_datetime(sched[\"date\"], format=\"%m/%d/%Y\", errors=\"coerce\")\n",
    "    sched = sched.sort_values(\"date\").reset_index(drop=True).head(int(n))\n",
    "    league_log[\"_DATE\"] = pd.to_datetime(league_log[\"GAME_DATE\"], errors=\"coerce\").dt.normalize()\n",
    "\n",
    "    missing = [fn for fn in [\n",
    "        \"get_pace_diff\", \"get_oreb_pct_relative\", \"get_dreb_pct_relative\"\n",
    "    ] if fn not in globals()]\n",
    "    if missing:\n",
    "        raise RuntimeError(f\"Missing in globals(): {', '.join(missing)}\")\n",
    "\n",
    "    rows = []\n",
    "    for i, g in sched.iterrows():\n",
    "        home = g[\"home_team\"]\n",
    "        away = g[\"away_team\"]\n",
    "        d = g[\"date\"]\n",
    "        dstr = d.strftime(\"%m/%d/%Y\") if pd.notnull(d) else str(g[\"date\"])\n",
    "\n",
    "        # --- Call your 3 feature functions (timed, read-only)\n",
    "        with muted_stdout(quiet):\n",
    "            t0 = time.perf_counter()\n",
    "            pace_val = get_pace_diff(home, away, season, season, dstr)\n",
    "            pace_t = time.perf_counter() - t0\n",
    "\n",
    "            t0 = time.perf_counter()\n",
    "            oreb_rel = get_oreb_pct_relative(home, away, season, season, dstr)\n",
    "            oreb_t = time.perf_counter() - t0\n",
    "\n",
    "            t0 = time.perf_counter()\n",
    "            dreb_rel = get_dreb_pct_relative(home, away, season, season, dstr)\n",
    "            dreb_t = time.perf_counter() - t0\n",
    "\n",
    "        # --- Team priors (running averages up to the day BEFORE)\n",
    "        from advanced_ledger import get_prior_pace, get_prior_oreb_pct, get_prior_dreb_pct\n",
    "        hid = get_team_id(home)\n",
    "        aid = get_team_id(away)\n",
    "        if hid is None or aid is None:\n",
    "            print(f\"\\n#{i+1} {season} {dstr}: {away} @ {home}\")\n",
    "            print(\"-\" * 70)\n",
    "            print(\"Error: could not resolve team IDs.\")\n",
    "            continue\n",
    "\n",
    "        dt = datetime.strptime(dstr, \"%m/%d/%Y\")\n",
    "\n",
    "        h_pace = get_prior_pace(season, hid, dt)\n",
    "        a_pace = get_prior_pace(season, aid, dt)\n",
    "        h_oreb = get_prior_oreb_pct(season, hid, dt)\n",
    "        a_oreb = get_prior_oreb_pct(season, aid, dt)\n",
    "        h_dreb = get_prior_dreb_pct(season, hid, dt)\n",
    "        a_dreb = get_prior_dreb_pct(season, aid, dt)\n",
    "\n",
    "        # Print block (values used by your features + priors they rely on)\n",
    "        print(f\"\\n#{i+1}  {season}  {dstr}:  {away} @ {home}\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"get_pace_diff:         {_fmt(pace_val)}   (time {pace_t:.3f}s)\")\n",
    "        print(f\"get_oreb_pct_relative: {_fmt(oreb_rel)}   (time {oreb_t:.3f}s)\")\n",
    "        print(f\"get_dreb_pct_relative: {_fmt(dreb_rel)}   (time {dreb_t:.3f}s)\")\n",
    "        print(\"Team priors (running avgs up to day-before):\")\n",
    "        print(f\"  HOME {home:>16} | PACE={_fmt(h_pace)}  OREB_PCT={_fmt(h_oreb)}  DREB_PCT={_fmt(h_dreb)}\")\n",
    "        print(f\"  AWAY {away:>16} | PACE={_fmt(a_pace)}  OREB_PCT={_fmt(a_oreb)}  DREB_PCT={_fmt(a_dreb)}\")\n",
    "\n",
    "        # --- MUTATE: append this game to the ledger (idempotent)\n",
    "        gid = _resolve_game_id(d, home, away)\n",
    "        if gid is None:\n",
    "            print(\"  [warn] Could not resolve GAME_ID; ledger not updated for this game.\")\n",
    "        else:\n",
    "            with muted_stdout(quiet):\n",
    "                append_adv_game(season, gid)\n",
    "            print(f\"  [ledger] appended GAME_ID={gid}\")\n",
    "\n",
    "        rows.append({\n",
    "            \"idx\": i+1, \"season\": season, \"date\": dstr,\n",
    "            \"away_team\": away, \"home_team\": home,\n",
    "            \"pace_diff\": pace_val,\n",
    "            \"oreb_pct_relative\": oreb_rel,\n",
    "            \"dreb_pct_relative\": dreb_rel,\n",
    "            \"elapsed_pace\": pace_t,\n",
    "            \"elapsed_oreb_rel\": oreb_t,\n",
    "            \"elapsed_dreb_rel\": dreb_t,\n",
    "            \"home_pace_prior\": h_pace, \"home_oreb_pct_prior\": h_oreb, \"home_dreb_pct_prior\": h_dreb,\n",
    "            \"away_pace_prior\": a_pace, \"away_oreb_pct_prior\": a_oreb, \"away_dreb_pct_prior\": a_dreb,\n",
    "            \"game_id\": gid,\n",
    "        })\n",
    "\n",
    "    if return_df:\n",
    "        import pandas as pd\n",
    "        return pd.DataFrame(rows, columns=[\n",
    "            \"idx\",\"season\",\"date\",\"away_team\",\"home_team\",\"game_id\",\n",
    "            \"pace_diff\",\"oreb_pct_relative\",\"dreb_pct_relative\",\n",
    "            \"elapsed_pace\",\"elapsed_oreb_rel\",\"elapsed_dreb_rel\",\n",
    "            \"home_pace_prior\",\"home_oreb_pct_prior\",\"home_dreb_pct_prior\",\n",
    "            \"away_pace_prior\",\"away_oreb_pct_prior\",\"away_dreb_pct_prior\",\n",
    "        ])\n",
    "    return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#time_features_with_team_priors_first_n_games(n=100)\n",
    "\n",
    "#print(misc_ledger.get_pts_off_tov_rate_relative(\"Portland Trail Blazers\", \"Los Angeles Lakers\", \"2017-18\", \"2017-18\", \"10/18/2018\"))\n",
    "\n",
    "#print(getLeagueDashTeamStats(\"Portland Trail Blazers\", \"2017-18\", \"10/01/2017\", \"05/01/2018\", \"Misc\", \"PerGame\" ))\n",
    "\n",
    "#team_id = get_team_id(\"Portland Trail Blazers\")\n",
    "#print(get_prior_poss(season=\"2017-18\", team_id=team_id, game_date=\"10/18/2018\"))\n",
    "\n",
    "def show_team_advanced_ledger(\n",
    "    team: str | int,\n",
    "    season: str,\n",
    "    last: int | None = 20,\n",
    "    features: tuple[str, ...] = (\"PACE\", \"OREB_PCT\", \"DREB_PCT\", \"NET_RATING\"),\n",
    "):\n",
    "    \"\"\"\n",
    "    Read-only view of the advanced ledger for one team.\n",
    "    Prints GAME_DATE, GAME_ID, each feature and its *_prior (running avg up to previous game).\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from stats_getter import get_team_id\n",
    "    from advanced_ledger import _team_adv_slice  # cached, read-only\n",
    "\n",
    "    tid = team if isinstance(team, int) else get_team_id(str(team))\n",
    "    if tid is None:\n",
    "        raise ValueError(f\"Could not resolve team '{team}' to a TEAM_ID\")\n",
    "\n",
    "    df = _team_adv_slice(season, int(tid)).copy()\n",
    "    if df.empty:\n",
    "        print(f\"[{season}] Ledger is empty for TEAM_ID={tid}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    cols = [\"GAME_DATE\", \"GAME_ID\", \"TEAM_ID\", \"TEAM_ABBREVIATION\"]\n",
    "    for m in features:\n",
    "        if m in df.columns:\n",
    "            cols.append(m)\n",
    "        if f\"{m}_prior\" in df.columns:\n",
    "            cols.append(f\"{m}_prior\")\n",
    "\n",
    "    view = df.loc[:, [c for c in cols if c in df.columns]]\n",
    "    if last is not None:\n",
    "        view = view.tail(int(last))\n",
    "\n",
    "    # Pretty print\n",
    "    with pd.option_context(\"display.max_rows\", None, \"display.width\", 160, \"display.float_format\", \"{:.4f}\".format):\n",
    "        print(view)\n",
    "\n",
    "    return view\n",
    "# Last 15 rows for ATL in 2019-20\n",
    "\n",
    "def debug_prior_pace_breakdown(team_name: str, season: str, date_str: str):\n",
    "    \"\"\"\n",
    "    Explain where get_prior_pace(season, team_id, date) is coming from.\n",
    "\n",
    "    Prints:\n",
    "      - which branch was used (ledger prior row, current-season predate aggregate, or previous-season fallback)\n",
    "      - current-season simple mean of game PACE before `date`\n",
    "      - current-season totals-weighted PACE before `date`  (= 48 * sum(POSS) / sum(MIN))\n",
    "      - previous-season PACE from LeagueDashTeamStats (for reference)\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    from stats_getter import get_team_id, getLeagueDashTeamStats\n",
    "    from advanced_ledger import _team_adv_slice, get_prior_pace\n",
    "\n",
    "    tid = get_team_id(team_name)\n",
    "    if tid is None:\n",
    "        print(f\"Could not resolve TEAM_ID for {team_name}\")\n",
    "        return\n",
    "\n",
    "    dt = datetime.strptime(date_str, \"%m/%d/%Y\")\n",
    "\n",
    "    # What get_prior_pace actually returns (the value you printed)\n",
    "    val = get_prior_pace(season, tid, dt)\n",
    "\n",
    "    # Pull this season's ledger slice\n",
    "    df = _team_adv_slice(season, tid).copy()\n",
    "    used_branch = \"unknown\"\n",
    "    row_today = df[(df[\"GAME_DATE\"] == pd.to_datetime(dt.date()))]\n",
    "    if not row_today.empty and pd.notna(row_today[\"PACE_prior\"].iloc[0]):\n",
    "        used_branch = \"ledger_row_prior (shift/expanding mean)\"\n",
    "    else:\n",
    "        # Did we even have earlier rows this season?\n",
    "        earlier = df[df[\"GAME_DATE\"] < pd.to_datetime(dt.date())]\n",
    "        if not earlier.empty:\n",
    "            used_branch = \"current_season_predate_aggregate (no ensured row)\"\n",
    "        else:\n",
    "            used_branch = \"previous_season_fallback\"\n",
    "\n",
    "    # Current-season aggregates before date\n",
    "    if 'POSS' in df.columns and 'MIN' in df.columns:\n",
    "        poss_sum = pd.to_numeric(df.loc[df[\"GAME_DATE\"] < pd.to_datetime(dt.date()), \"POSS\"], errors=\"coerce\").sum()\n",
    "        min_sum  = pd.to_numeric(df.loc[df[\"GAME_DATE\"] < pd.to_datetime(dt.date()), \"MIN\"],  errors=\"coerce\").sum()\n",
    "        pace_totals = 48.0 * (poss_sum / min_sum) if min_sum else float(\"nan\")\n",
    "    else:\n",
    "        poss_sum = min_sum = float(\"nan\")\n",
    "        pace_totals = float(\"nan\")\n",
    "\n",
    "    pace_simple = pd.to_numeric(\n",
    "        df.loc[df[\"GAME_DATE\"] < pd.to_datetime(dt.date()), \"PACE\"], errors=\"coerce\"\n",
    "    ).dropna().mean()\n",
    "\n",
    "    # Previous-season reference (full regular season)\n",
    "    prev_start = int(season.split(\"-\")[0]) - 1\n",
    "    prev_season = f\"{prev_start}-{str(prev_start+1)[-2:]}\"\n",
    "    prev_df = getLeagueDashTeamStats(\n",
    "        team_name=team_name,\n",
    "        season=prev_season,\n",
    "        date_from=f\"10/01/{prev_start}\",\n",
    "        date_to=f\"05/01/{prev_start+1}\",\n",
    "        measure_type=\"Advanced\",\n",
    "        per_mode=\"PerGame\",\n",
    "    )\n",
    "    prev_pace = float(prev_df[\"PACE\"].iloc[0]) if not prev_df.empty else float(\"nan\")\n",
    "\n",
    "    print(f\"\\n=== debug_prior_pace_breakdown ===\")\n",
    "    print(f\"team={team_name}  season={season}  date={date_str}\")\n",
    "    print(f\"get_prior_pace -> {val:.4f}  (branch: {used_branch})\")\n",
    "    print(f\"current-season before {date_str}:\")\n",
    "    print(f\"  simple mean of game PACE      = {pace_simple:.4f}\")\n",
    "    print(f\"  totals-weighted PACE          = {pace_totals:.4f}   (48 * sum(POSS)/sum(MIN))\")\n",
    "    print(f\"previous-season full reg season:\")\n",
    "    print(f\"  {prev_season} PACE (PerGame)  = {prev_pace:.4f}\")\n",
    "\n",
    "    \n",
    "def debug_calc_adv_only(home_team, away_team, date, season,\n",
    "                        mutate_ledgers: bool = True,\n",
    "                        precision: int = 6, quiet: bool = False):\n",
    "    \"\"\"\n",
    "    Replica-style debug helper for calculate_game_features:\n",
    "      - Calls the SAME feature functions you use in calculate_game_features:\n",
    "          get_pace_diff, get_oreb_pct_relative, get_dreb_pct_relative\n",
    "      - Prints those 3 feature values\n",
    "      - Prints each team's running average (prior) up to the *day before* the game\n",
    "      - Mutates ledgers the same way your pipeline does: append current game AFTER printing\n",
    "      - No bulky ensure_* sweeps\n",
    "    \"\"\"\n",
    "    import math, time\n",
    "    from datetime import datetime\n",
    "    import pandas as pd\n",
    "\n",
    "    # ---- match calculate_game_features date handling ----\n",
    "    date_str = date if isinstance(date, str) else date.strftime(\"%m/%d/%Y\")\n",
    "    dt = datetime.strptime(date_str, \"%m/%d/%Y\")\n",
    "\n",
    "    # ---- feature calls (identical call shapes) ----\n",
    "    t0 = time.perf_counter()\n",
    "    pace_diff = get_pace_diff(home_team, away_team, season, season, date_str)\n",
    "    t_pace = time.perf_counter() - t0\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    oreb_rel = get_oreb_pct_relative(home_team, away_team, season, season, date_str)\n",
    "    t_oreb = time.perf_counter() - t0\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    dreb_rel = get_dreb_pct_relative(home_team, away_team, season, season, date_str)\n",
    "    t_dreb = time.perf_counter() - t0\n",
    "\n",
    "    # ---- priors (running avgs up to day-before) ----\n",
    "    from stats_getter import get_team_id\n",
    "    from advanced_ledger import get_prior_pace, get_prior_oreb_pct, get_prior_dreb_pct\n",
    "\n",
    "    hid = get_team_id(home_team)\n",
    "    aid = get_team_id(away_team)\n",
    "\n",
    "    def _fmt(x):\n",
    "        try:\n",
    "            xf = float(x)\n",
    "            if math.isnan(xf): return \"nan\"\n",
    "            return f\"{xf:.{precision}g}\"\n",
    "        except Exception:\n",
    "            return str(x)\n",
    "\n",
    "    h_pace = get_prior_pace(season, hid, dt) if hid is not None else float(\"nan\")\n",
    "    a_pace = get_prior_pace(season, aid, dt) if aid is not None else float(\"nan\")\n",
    "    h_oreb = get_prior_oreb_pct(season, hid, dt) if hid is not None else float(\"nan\")\n",
    "    a_oreb = get_prior_oreb_pct(season, aid, dt) if aid is not None else float(\"nan\")\n",
    "    h_dreb = get_prior_dreb_pct(season, hid, dt) if hid is not None else float(\"nan\")\n",
    "    a_dreb = get_prior_dreb_pct(season, aid, dt) if aid is not None else float(\"nan\")\n",
    "\n",
    "    # ---- print exactly what you need (and nothing else) ----\n",
    "    if not quiet:\n",
    "        print(f\"{season}  {date_str}:  {away_team} @ {home_team}\")\n",
    "        print(\"-\" * 75)\n",
    "        print(f\"get_pace_diff:         {_fmt(pace_diff)}   (time {t_pace:.3f}s)\")\n",
    "        print(f\"get_oreb_pct_relative: {_fmt(oreb_rel)}    (time {t_oreb:.3f}s)\")\n",
    "        print(f\"get_dreb_pct_relative: {_fmt(dreb_rel)}    (time {t_dreb:.3f}s)\")\n",
    "        print(\"Team priors (running avgs up to day-before):\")\n",
    "        print(f\"  HOME {home_team:>18} | PACE={_fmt(h_pace)}  OREB_PCT={_fmt(h_oreb)}  DREB_PCT={_fmt(h_dreb)}\")\n",
    "        print(f\"  AWAY {away_team:>18} | PACE={_fmt(a_pace)}  OREB_PCT={_fmt(a_oreb)}  DREB_PCT={_fmt(a_dreb)}\")\n",
    "\n",
    "    # ---- mutate ledgers AFTER computing features (so priors were truly 'up to day-before') ----\n",
    "    if mutate_ledgers:\n",
    "        # resolve game_id from league log (same approach you used elsewhere)\n",
    "        from stats_getter import get_league_game_log\n",
    "        from advanced_ledger import append_adv_game\n",
    "\n",
    "        league_log = get_league_game_log(season).copy()\n",
    "        league_log[\"_DATE\"] = pd.to_datetime(league_log[\"GAME_DATE\"], errors=\"coerce\").dt.normalize()\n",
    "        dnorm = pd.to_datetime(date_str, errors=\"coerce\").normalize()\n",
    "\n",
    "        # find the GAME_ID that has both teams on that date\n",
    "        gids = league_log.loc[\n",
    "            (league_log[\"_DATE\"] == dnorm) &\n",
    "            (league_log[\"TEAM_ID\"].isin([hid, aid]))\n",
    "        ][\"GAME_ID\"].dropna().unique().tolist()\n",
    "\n",
    "        gid = None\n",
    "        if len(gids) == 1:\n",
    "            gid = str(gids[0])\n",
    "        else:\n",
    "            # if multiple rows, pick the one whose entries include both teams\n",
    "            for g in gids:\n",
    "                sub = league_log[league_log[\"GAME_ID\"] == g]\n",
    "                if set(sub[\"TEAM_ID\"].unique()).issuperset({hid, aid}):\n",
    "                    gid = str(g); break\n",
    "\n",
    "        if gid:\n",
    "            append_adv_game(season, gid)\n",
    "            if not quiet:\n",
    "                print(f\"[ledger] appended GAME_ID={gid}\")\n",
    "        else:\n",
    "            if not quiet:\n",
    "                print(\"[warn] Could not resolve GAME_ID; ledger not updated for this game.\")\n",
    "\n",
    "    # return values so you can assert in tests if you want\n",
    "    return {\n",
    "        \"pace_diff\": pace_diff,\n",
    "        \"oreb_pct_relative\": oreb_rel,\n",
    "        \"dreb_pct_relative\": dreb_rel,\n",
    "        \"home_pace_prior\": h_pace, \"home_oreb_pct_prior\": h_oreb, \"home_dreb_pct_prior\": h_dreb,\n",
    "        \"away_pace_prior\": a_pace, \"away_oreb_pct_prior\": a_oreb, \"away_dreb_pct_prior\": a_dreb,\n",
    "    }\n",
    "\n",
    "def debug_adv_only_first_n(n: int, season: str = \"2024-25\", quiet: bool = False):\n",
    "    import pandas as pd\n",
    "\n",
    "    sched = get_season_games(season).copy()\n",
    "    sched[\"date\"] = pd.to_datetime(sched[\"date\"], errors=\"coerce\")\n",
    "    sched = sched.sort_values(\"date\").head(int(n)).reset_index(drop=True)\n",
    "\n",
    "    out = []\n",
    "    for _, g in sched.iterrows():\n",
    "        out.append(\n",
    "            debug_calc_adv_only(\n",
    "                g[\"home_team\"], g[\"away_team\"], g[\"date\"], season,\n",
    "                mutate_ledgers=True, quiet=quiet\n",
    "            )\n",
    "        )\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#debug_adv_only_first_n(n=100)\n",
    "\n",
    "#debug_prior_pace_breakdown(\"Milwaukee Bucks\", \"2024-25\", \"10/31/2024\")\n",
    "\n",
    "#time_features_with_team_priors_first_n_games_MUTATING(n=100)\n",
    "#show_team_advanced_ledger(\"Brooklyn Nets\", \"2024-25\", last=100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# All rows for SAS with an expanded feature set\n",
    "#show_team_advanced_ledger(1610612759, \"2019-20\", last=None, features=(\"PACE\",\"EFG_PCT\",\"TOV_PCT\",\"OREB_PCT\",\"DREB_PCT\"))\n",
    "\n",
    "from cache_clearer import clear_all_ledgers, clear_everything\n",
    "#from cache_manager import stats_cache\n",
    "#stats_cache.clear_memory()        # wipe RAM\n",
    "#stats_cache.clear_disk(None)      # wipe ALL on-disk entries\n",
    "\n",
    "\n",
    "from cache_manager import stats_cache\n",
    "#stats_cache.clear_memory()        # wipe RAM\n",
    "#stats_cache.clear_disk(None)      # wipe ALL on-disk entries\n",
    "\n",
    "#print(getLeagueDashTeamStats(team_name=\"Los Angeles Lakers\",season=\"2018-19\", measure_type=\"Misc\", per_mode=\"PerGame\"))\n",
    "\n",
    "#print(hustle_ledger.show_team_hustle_ledger(\"2017-18\", \"Boston Celtics\", 100))\n",
    "# wipe ledgers only\n",
    "#clear_all_ledgers()\n",
    "\n",
    "# wipe ledgers + endpoint caches from cache_manager\n",
    "#clear_everything(also_endpoint_cache=True)\n",
    "\n",
    "#debug_netrtg_only_first_n(n=100)\n",
    "\n",
    "\n",
    "#print(get_league_game_log(\"2022-23\"))\n",
    "\n",
    "import os\n",
    "#os.environ[\"NBA_PACING_PROFILE\"] = \"A\"  # or \"B\"\n",
    "#df = load_all_features(seasons=[\"2022-23\"], output_file=\"tmp_features.csv\")\n",
    "\n",
    "#print(get_pfd_diff(\"Los Angeles Lakers\", \"Los Angeles Clippers\", \"2018-19\", \"2018-19\", \"10/22/2019\"))\n",
    "\n",
    "#print(get_netrtg_diff_prev_season(\"Cleveland Cavaliers\", \"2017-18\", \"10/18/2018\"))\n",
    "#print(get_netrtg_diff_prev_season(\"Boston Celtics\", \"2017-18\", \"10/18/2018\"))\n",
    "#print(get_corner_3pt_rate(\"Portland Trail Blazers\", \"Miami Heat\", \"2017-18\", \"2017-18\", \"10/18/2018\"))\n",
    "\n",
    "#print(get_corner_3pt_rate(\"Cleveland Cavaliers\", \"Boston Celtics\", \"2016-17\", \"2016-17\", \"10/17/2017\"))\n",
    "#print(debug_adv_only_first_n(n=100))\n",
    "\n",
    "#print(calculate_game_features(\"Los Angeles Lakers\", \"LA Clippers\", \"10/19/2017\", \"2017-18\"))\n",
    "\n",
    "#print(corner_3pt_rate(\"Portland Trail Blazers\", \"Indiana Pacers\", \"2018-19\", \"2018-19\", \"10/29/2019\"))\n",
    "#print(_date_window_for_season(\"2017-18\"))\n",
    "#print()\n",
    "\n",
    "#print(contested_3pt_rate(\"Boston Celtics\", \"Cleveland Cavaliers\", \"2016-17\", \"2016-17\", \"10/17/2017\"))\n",
    "\n",
    "\n",
    "import stats_getter as sg\n",
    "import pandas as pd\n",
    "\n",
    "season = \"2022-23\"   # try one that printed 0 games\n",
    "\n",
    "df = sg.get_league_game_log(season)\n",
    "print(\"league log shape:\", None if df is None else df.shape)\n",
    "print(df.head(3) if df is not None else None)\n",
    "\n",
    "# If df is non-empty, check your scheduler’s filters step-by-step.\n",
    "g = df.copy()\n",
    "g[\"GAME_DATE\"] = pd.to_datetime(g[\"GAME_DATE\"], errors=\"coerce\").dt.normalize()\n",
    "print(\"after date normalize:\", g.shape)\n",
    "\n",
    "# If you filter to Regular Season anywhere, check the column and values:\n",
    "if \"SEASON_TYPE\" in g.columns:\n",
    "    g = g[g[\"SEASON_TYPE\"].str.contains(\"Regular\", case=False, na=False)]\n",
    "    print(\"after Regular Season filter:\", g.shape)\n",
    "\n",
    "# If you route by worker via modulo, emulate the predicate you use:\n",
    "# e.g., suppose you do GAME_ID % 5 == idx, test it:\n",
    "idx = \"E\"  # your NBA_WORKER\n",
    "N   = 5\n",
    "# Replace this with the exact function you use to map worker->index and to hash GAME_ID\n",
    "# Example shard check (toy):\n",
    "# gi = pd.to_numeric(g[\"GAME_ID\"], errors=\"coerce\")\n",
    "# g = g[gi % N == 4]  # if E->4\n",
    "print(\"after routing predicate:\", g.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8de02a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fcf91c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5288df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638b86a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec886dba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
